[TOC]

# 对微服务的理解

http://dockone.io/article/3687

# 限流

下面的方案都是单机版本的，在分布式环境下可以把限流的实例放到Redis里，或者直接使用Lua脚本实现，保证并发安全。

## 固定窗口

规定单位时间内可访问的次数，比如规定接口一分钟内只能访问10次，以第一次请求为起始，计数1，一分钟内计数超过10后，后续的请求直接拒绝，只能等到这一分钟结束后，重置计数，重新开始计数。

但是这样有个问题，如果在大部分请求集中在第一个窗口的后10s内，和第二个窗口的前10s内，虽然他们都符合限流策略，但是在临界的20s内，请求还是有可能压垮系统。

算法Demo：

```go
type fixWinLimiter struct {
	lock            *sync.Mutex
	maxLimitCount    int64   // 最大限制数
	currentCount     int64   // 当前计数
	fixInterval      int64   // 为了简化，单位设置为秒
	lastReqStartAt   int64   // 秒级时间戳
}

func NewFixWinLimit(fixInterval int64, maxLimitCount int64) *fixWinLimiter {
	return &fixWinLimiter{
		lock:           new(sync.Mutex),
		maxLimitCount:  maxLimitCount,
		fixInterval:    fixInterval,
	}
}

func (f *fixWinLimiter) IsPass() bool {
	f.lock.Lock()
	defer f.lock.Unlock()
	now := time.Now().Unix()
	if now - f.lastReqStartAt > f.fixInterval {
		f.currentCount = 0
		f.lastReqStartAt = now
		return true
	}
	if f.currentCount + 1 >= f.maxLimitCount {
		return false
	}
	f.currentCount++
	return true
}

// 测试
func main() {
    // 10s内只允许通过10次
	f1 := NewFixWinLimit(10, 10)
	for i := 0; i < 20; i++ {
		go func(index int) {
			if f1.IsPass() {
				fmt.Println(fmt.Sprintf("pass: %d", index))
			} else {
				fmt.Println(fmt.Sprintf("no pass: %d", index))
			}
		}(i)
	}
	time.Sleep(100 * time.Second)
}
```

## 滑动窗口

与固定窗口类似，只是以时间片划分，比如规定窗口一秒内只能请求5次，每次请求时会按照前一秒内的请求数量进行判断，超过则拒绝。

这种算法本质上只是把固定窗口计数限流的时间片变小了，仍然有可能出现固定窗口计数限流的临界点问题。

算法Demo：

```go
type slidingWinLimiter struct {
	lock          *sync.Mutex
	limitInterval int64 // 限制的时间间隔
	lastReqAt     int64 // 上一次请求的时间

	winCount           []int64 // 窗口计数
	currentWinIndex    int64   // 当前窗口索引
	currentWinMaxLimit int64   // 当前窗口最大限制数
	winNum             int64   // 窗口数量
}

func NewSlidingWinLimiter(limitInterval int64, winMaxLimitCount int64, winNum int64) *slidingWinLimiter {
	return &slidingWinLimiter{
		lock:               new(sync.Mutex),
		limitInterval:      limitInterval,
		lastReqAt:          time.Now().Unix(),
		winCount:           make([]int64, winNum),
		currentWinMaxLimit: winMaxLimitCount,
		winNum:             winNum,
	}
}

func (s *slidingWinLimiter) IsPass() bool {
	s.lock.Lock()
	defer s.lock.Unlock()
	now := time.Now().Unix()
	// 每个窗口的时间间隔
	eachWinInterval := float64(s.limitInterval) / float64(s.winNum)
	// 判断前后两次请求的时间差是否在当前窗口内，不是则重置当前窗口，使用下一个窗口
	if float64(now-s.lastReqAt) > eachWinInterval {
		s.winCount[s.currentWinIndex] = 0
		s.currentWinIndex = (s.currentWinIndex + 1) % s.winNum
		s.lastReqAt = now
	}
	// 判断是否超过当前窗口的限制
	if s.winCount[s.currentWinIndex] >= s.currentWinMaxLimit {
		return false
	}
	s.winCount[s.currentWinIndex]++
	return true
}

func main() {
	f1 := NewSlidingWinLimiter(1, 10, 1)
	for i := 0; i < 20; i++ {
		go func(index int) {
			if f1.IsPass() {
				fmt.Println(fmt.Sprintf("pass: %d", index))
			} else {
				fmt.Println(fmt.Sprintf("no pass: %d", index))
			}
		}(i)
	}
	time.Sleep(100 * time.Second)
}
```

## 漏桶

控制流水，水(请求)持续加入桶中，底部以恒定速度流出，如果加水速度大于漏出速度，水则溢出，请求拒绝。即宽进严出，无论请求多少，请求的速率有多大，都按照固定的速率流出。

一般用在对第三方提供服务的请求限制上，比如我们服务接入shopify的服务，为了不触发shopify的限流，就可以使用漏桶算法。

算法Demo：

```go
type bucketLimiter struct {
	lock          *sync.Mutex
	lastReqAt     int64 // 单位：秒
	bucketCap     int64 // 桶的容量
	bucketBalance int64 // 桶的余量
	rate          int64 // 每时间单位内漏桶的漏出速率
}

func NewBucketLimiter(rate int64, bucketCap int64) *bucketLimiter {
	return &bucketLimiter{
		lock:          new(sync.Mutex),
		bucketCap:     bucketCap,
		bucketBalance: 0,
		rate:          rate,
		lastReqAt:     time.Now().Unix(),
	}
}

func (b *bucketLimiter) IsPass() bool {
	b.lock.Lock()
	defer b.lock.Unlock()
	now := time.Now().Unix()
	// 计算时间差内可通过的计数量
	diffInterval := now - b.lastReqAt
	diffCount := diffInterval * b.rate
	// 计算桶中剩余的量
	b.bucketBalance -= diffCount
	if b.bucketBalance < 0 {
		b.bucketBalance = 0
	}
	b.lastReqAt = now
	// 判断是否加水后是否溢出
	if b.bucketBalance+1 <= b.bucketCap {
		b.bucketBalance++
		return true
	}
	return false
}

// 测试
func main() {
    	// 单位时间内漏出速度是2，桶的容量是5
	f1 := NewBucketLimiter(2, 5)
	for i := 0; i < 20; i++ {
		go func(index int) {
			if f1.IsPass() {
				fmt.Println(fmt.Sprintf("pass: %d", index))
			} else {
				fmt.Println(fmt.Sprintf("no pass: %d", index))
			}
		}(i)
	}
	time.Sleep(100 * time.Second)
}
```


## 令牌桶

类似信号量，令牌桶会单独维护一个令牌的存储桶，为这个桶设置一个上限，同时又会有令牌持续将放入桶中，以应对一定的突发流量，比如桶的上限是1000，每秒持续放入1000个令牌，当前1s有800个请求发生并消耗令牌，由于每秒会放入1000个令牌，后1s就有1200个令牌可以被消耗，因此下一秒可以应对1200个请求。

漏桶和令牌桶的区别：漏桶是限制流出速度，令牌桶是限制流入速度。

算法Demo：

```go
type tokenLimiter struct {
	lock           *sync.Mutex
	lastReqAt      int64 // 单位：秒
	availableToken int64 // 可用的令牌数量
	maxTokenLimit  int64 // 最大令牌数量
	rate           int64 // 每时间单位内token的加入速率
}

func NewTokenLimiter(rate int64, maxTokenLimit int64) *tokenLimiter {
	return &tokenLimiter{
		lock:           new(sync.Mutex),
		lastReqAt:      time.Now().Unix(),
		maxTokenLimit:  maxTokenLimit,
		availableToken: maxTokenLimit,
		rate:           rate,
	}
}

func (t *tokenLimiter) IsPass() bool {
	t.lock.Lock()
	defer t.lock.Unlock()
	now := time.Now().Unix()
	// 计算时间差内可通过的计数量
	diffInterval := now - t.lastReqAt
	diffCount := diffInterval * t.rate
	// 把可通过的量加入令牌桶里
	t.availableToken += diffCount
	if t.availableToken > t.maxTokenLimit {
		t.availableToken = t.maxTokenLimit
	}
	t.lastReqAt = now
	// 判断是否有令牌可取
	if t.availableToken > 0 {
		t.availableToken--
		return true
	}
	return false
}

// 测试
func main() {
    	// 单位时间内漏出速度是2，桶的容量是5
	f1 := NewTokenLimiter(2, 5)
	for i := 0; i < 20; i++ {
		go func(index int) {
			if f1.IsPass() {
				fmt.Println(fmt.Sprintf("pass: %d", index))
			} else {
				fmt.Println(fmt.Sprintf("no pass: %d", index))
			}
		}(i)
	}
	time.Sleep(100 * time.Second)
}
```

# 熔断

熔断一般分为三种状态：

* Closed关闭：服务正常时，熔断处于关闭状态
* Open开启：当我们设定10s的滑动窗口内错误率达90%，则从Closed变为Open状态
* HalfOpen半开启：再经过10s的窗口期，此时从Open状态转为HalfOpen状态，按照 `0.5 * (Now() - Start()) / Duration `的公式放量，直到成功率变为90%，转为Closed状态，否则转为Open状态。

滑动窗口的时间不能设置太长，否则熔断恢复时间也会变长；错误统计只统计系统异常不通知业务异常。

# 负载均衡

## 常用算法

- 轮询：按请求的顺序分配给各个服务器，适用于各台服务器性能相同
- 加权轮询：给各个服务器附上权重值，按权重的高低分配请求，适用于各台服务器性能不同，性能高的服务器权重也高
- 加权随机轮询：随机 + 二分查找的方式负载均衡，时间复杂度为O(logn)
- 最少链接：将请求发送给当前最少连接数的服务器上
- 加权最少链接：在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数
- IP地址哈希：哈希均匀分布
- 二次随机选择轮询：适合后端节点权重一致的情况，通过两次随机算法，获取到两个节点，对比节点CPU等信息，选择最优节点；（比较流行）
- 会话保持：根据客户端IP或cookie进行会话保持，同一个客户端每次选取后端节点的IP保持一致，适用于节点保持登录验证会话的场景，比较少用。

## 探活

负载均衡器上面一般会挂一个服务的多个复制集，进行流量的负载均衡，因此需要检查这多个复制集的健康情况，保证流量能正确路由到可用节点上。

### 主动健康检查

设定一定时间间隔内对各个复制集执行ping操作，一般在获取节点数量过少的场景下才触发，避免长时间频繁的ping操作增加节点负担。

比如通过当前节点数与15分钟前的节点数的比较，当小于80%时触发主动健康检查。

### 被动健康检查

通过检查节点真实流量的响应结果，判断节点是否正常

# 服务注册与发现

## 基本功能

1. 提供服务地址与域名的映射注册、查找和更新

2. 提供多种负载均衡方案

3. 健康检查，比如心跳检测

   * **服务主动探活**：服务注册到注册中心后，定时发送续租请求到注册中心，表明自己存活

     优点：该方案可最大程度**避免IP重用**导致节点在旧服务依然存活的问题(比如k8s环境)

     缺点：造成注册中心写操作变多，特别是在强一致性的注册中心上，频繁的节点变更会导致产生大量的通知事件，在同步到多个注册中心复制集时性能不佳；另外，仍然可能发生服务虽无法对外提供服务了，但仍然可以发送续租请求；面对不同的客户端需要提供不同语言的SDK

   * **注册中心主动探活**：服务提供健康检查接口，比如/ping，注册中心定时访问验证节点存活；k8s的Pod探针机制

     优点：一定程度上解决服务主动探活不能说明服务健康的问题

     缺点：IP重用问题，比如A、B两个服务都有相同的端口和/ping接口做健康检查，但是当发生服务替换时，无法区分是哪个服务，除非加上名称检查

   * 服务外挂一个负载均衡器实现服务探活、与注册中心的通信

     优点：注册中心和服务均不需要主动探活，均交由负载均衡器实现

     缺点：需要外挂的负载均衡器，增加成本

4. 注册中心需要保证CP或者AP

5. 将上述功能包装成SDK，简化使用

## 可能遇到的问题

1. 注册中心故障时，服务注册功能失效，服务也无法执行扩容操作，因此会在服务内缓存服务注册表，保证服务可通信；
2. 优先使用缓存的服务注册表，当接收到的服务注册表的节点过少时，放弃使用；
3. 通过在负载均衡器中加入被动健康检查和主动健康检查来剔除服务注册表中失效的节点，保证服务注册表的可用性
4. 参考Service Mesh的Envoy设计，不完全信任注册中心推送过来的服务注册表；

| 发现状态 | 健康检查成功 | 健康检查失败         |
| -------- | ------------ | -------------------- |
| 发现     | 路由         | 不路由               |
| 未发现   | 路由         | 不路由、剔除失败节点 |

5. 面对节点和服务频繁变更，导致广播风暴的场景，可以通过合并设定时间内产生的消息后再进行推送，目的是为了减少广播次数，但是这样会影响消息的时效性，要注意设定的时间不宜过长。

## 常见的注册中心区别

| 特征           | Nocas                         | Eureka | Zookeeper  | Consul               | ETCD   |
| -------------- | ----------------------------- | ------ | ---------- | -------------------- | ------ |
| 一致性协议     | AP或CP                        | AP     | CP         | CP                   | CP     |
| 健康检查       | TCP、HTTP、MySQL、Client Beat | TTL    | Keep Alive | TCP、HTTP、gRPC、Cmd | TTL    |
| 网络异常保护   | 支持                          | 支持   | 不支持     | 支持                 | 不支持 |
| 雪崩保护       | 支持                          | 支持   | 不支持     | 不支持               | 不支持 |
| 自动注销实例   | 支持                          | 支持   | 支持       | 不支持               | 支持   |
| 访问协议       | HTTP、DNS                     | HTTP   | TCP        | HTTP、DNS            | HTTP   |
| 跨注册中心同步 | 支持                          | 不支持 | 不支持     | 支持                 | 不支持 |
| K8s集成        | 支持                          | 不支持 | 不支持     | 支持                 | 支持   |
| 语言实现       | Java                          | Java   | Java       | GO                   | GO     |

一般来说，注册中心对一致性的要求不是很高，因为节点的注册和反注册后通知到客户端也需要时间；对可用性的优先级较高。

这里再说下K8s提供的默认服务发现（1.12后默认使用coreDNS），通过为Pod挂一个Service 或者 Pod 定义了hostname + subdomain，k8s也会为其生成Pod的 DNS A记录，然后 k8s 会把 Service 或 Pod 产生的DNS记录写入 CoreDNS 的 cache 或者 ETCD 中，同时在Pod的/etc/resolv.conf文件中添加CoreDNS服务的访问配置，Pod即可通过名称进行访问（同一命名空间下可以直接使用Pod名称进行访问，不同命名空间需要 Pod名称.命名空间名称 访问，或者直接使用Service的DNS名称访问）。

CoreDNS会监听集群内所有Service API，当服务不可用时移除记录，在新服务创建时插入新记录，这些记录会存储在CoreDNS的cache或者ETCD中。

参考：https://github.com/kubernetes/dns/blob/master/docs/specification.md

比如有如下 /etc/resolv.conf文件

```sh
# /etc/resolv.conf
nameserver 10.100.0.10  # coreDNS的IP
search cafe.svc.cluster.local svc.cluster.local cluster.local us-west-2.compute.internal
options ndots:5
```

其含义是：DNS 服务器为 10.100.0.10，当查询关键词中 `.` 的数量少于 5 个，则根据 search 中配置的域名进行查询，当查询都没有返回正确响应时再尝试直接查询关键词本身。

比如执行 host -v cn.bing.com 时会看到下面即此查询

```sh
Trying "cn.bing.com.cafe.svc.cluster.local"
Trying "cn.bing.com.svc.cluster.local"
Trying "cn.bing.com.cluster.local"
Trying "cn.bing.com.us-west-2.compute.internal"
Trying "cn.bing.com"
...
```

# 
