[TOC]

# 数据类型及结构

## 数据类型

String、List(一般当成队列，尽量少使用随机读写)、Hash、Set、ZSet

String类型下还有一种扩展类型：Bitmap。原理：String类型会保存二进制字节数组，对于这个字节数组的每个bit来表示一个元素的二值状态。

此外还有扩展类型：HyperLogLog、Geo

## 底层数据结构

* String：简单动态字符串(SDS)
* List：双向链表 + 压缩列表
* Hash：哈希表 + 压缩列表
* Set：整数数组+ 哈希表
* ZSet：跳表 + 压缩列表

### 简单动态字符串(SDS)

Redis的String类型底层有两种保存形式，当保存的是64位有符号整数时，String类型会保存为一个9字节的Long类型整数；当保存的数据包含字符时，String类型就会用简单动态字符串SDS。

简单动态字符串SDS由三个部分组成：

* buf：是字节数组，保存实际数据，结束标志位是"/0"。
* len：表示buf已用长度，占4字节
* alloc：表示buf的实际分配长度，一般大于len

此外，对于每种数据类型，Redis会使用RedisObject来记录一些元数据，比如最后以此访问时间，引用次数等，RedisObject包含了8个字节的元数据和一个8字节指针，指针指向具体的数据类型的实际数据所在。

对于String类型的RedisObject：

* 当保存的是Long类型整数时，RedisObject中的指针直接就是整数数据，不用额外的指针指向整数；
* 当保存的是字符串时，如果字符串<=44字节，RedisObject中元数据，指针和SDS是一块连续的内存区域，避免内存碎片
* 当保存的是字符串时，如果字符串>44字节，RedisObject会给SDS分配独立的空间，并用指针指向SDS

![Redis String RedisObject: 来自极客时间Redis核心技术与实战](https://github.com/Nixum/Java-Note/raw/master/picture/Redis String RedisObject.png)

当使用String类型时，且value的类型是String时，如果value的长度太小，可能会出现元数据的大小比数据本身的大小还大，造成额外的内存开销。如果能替换成Long类型，实际存储的大小会大大降低。

### 哈希表

但无论值是什么类型的，所有的键值对会保存在**全局哈希表**中，便于快速找到对应的Key，哈希桶只会保存键值对的指针。全局哈希表中的桶每个元素entry由三个8字节指针组成，分别为key、value、next，但实际会占32字节，因为内存分配库jemalloc会分配最接近24的2的幂次数，所以是32，以减少频繁的分配次数。

因此，即使Redis里存在大量数据，也不影响查找的速度，毕竟都是根据Key进行hash就能找到对应的Value，真正有影响的是哈希表的在解决哈希冲突和rehash时带来的阻塞。

**Redis的哈希表使用拉链法解决哈希冲突。通过两个全局哈希表加快rehash的操作。**

处理全局哈希表有这种操作，Hash的数据结构也是这样的操作，本质是一样的。

当Redis生产RDB和AOF重写时，哈希表不会进行rehash。

#### rehash触发条件

装载因子：哈希表中所有entry的个数除以哈希表的哈希桶个数。

* 当装载因子>= 1，且哈希表被允许rehash，即此时没有进行RDB和AOF重写

* 当装载因子>= 5，因为此时数据量已远远大于哈希桶的个数了，此时会立马进行rehash

#### rehash过程

1. 默认使用哈希表1，此时哈希表2还没有被分配空间

2. 当数据增多至需要rehash时，为哈希表2分配空间，大小会比哈希表1大，比如大两倍

3. 把哈希表1中的数据重新映射并拷贝到哈希表2中

   **渐进式rehash**：解决大量数据在哈希表1和2之间拷贝，会导致Redis线程阻塞（因为单线程)。

   3.1 拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺便将该索引位置上的所有entries拷贝到哈希表2中；

   3.2 等待处理下一个请求时，再顺带拷贝哈希表1中该索引下一个索引位置的entries到哈希表2中；

   通过这两种方式，将一次性的大量拷贝分散到每次请求和等待间隙中。

   3.3 此外Redis本身也有一个**定时任务**在执行rehash，发生在空闲时间

4. 释放哈希表1的空间，此时哈希表1的空间被回收，原来的哈希表2变成哈希表1，哈希表1变成哈希表2

列表

对于Hash数据类型，底层有压缩列表和哈希表两种实现，当Hash 集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表，且之后不可逆。使用压缩列表时，底层是无法利用index查找，只能遍历查找。

### 压缩列表

本质上是一个数组，数组中每一个元素保存一个数据。但压缩列表在

* 表头有三个字段：zlbytes记录占用的内存字节数，可算出列表长度；zltail记录列表尾的偏移量，可算出尾节点到列表起始地址的字节数；zllen记录列表中的entry个数；
* 每个节点元素entry有四个字段：previous_entry_length记录前一个节点的长度；encoding记录content的数据类型和长度；content保存元素的值；len表示自身长度。
* 表尾有一字段：zlend用于标记列表末端。

数据类型List、Hash、ZSet都有使用到压缩列表。

压缩列表的优势在于存储结构，普通数组要求数组的每个元素的大小相同，但是当我们需要在每个元素中存储大小不同的字符串时，就会浪费存储空间，压缩列表就是会把每个元素多余的空间进行压缩，让每个元素紧密相连，再为每个元素增加一个长度，用于计算下一个元素在内存中的位置。

另外，在内存的地址查找时，在查找第一个和最后一个的时候有优势，可以利用这三个字段查到，是O(1)，但是因为存储紧凑的缘故，查找其他元素只能遍历，是O(n)。

压缩列表或者数组主要因为其数据结构紧凑，节省空间，避免内存碎片，提升内存利用率，线性顺序存储，对CPU高速缓存支持友好。对于查找的时间复杂度的优势提升不大。但是，由于压缩列表比较紧凑，在新增更新删除操作时可能会引发连锁更新，此时最坏为O(n^2)，但触发概率相对较低，利大于弊。

### 跳表

本质是为链表增加索引，建立多层索引，查找时从顶层的索引开始逐步往下层找，最终定位到元素，适用于范围查询的场景。查找的时间复杂度为O(logN)

### 时间复杂度

对各种数据类型操作的时间复杂度取决于底层的数据结构，对于Set，虽然名字看起来是集合，但由于底层是哈希表 + 数组，因此在SREM、SADD、SRANDMENBER命令时，时间复杂度都是O(1)

* 数据类型的范围查询，都需要进行遍历操作，一般都是比较耗时的。比如List的LRANGE、ZSet的ZRANGE、Set的SMEMBERS等

* 数据类型的统计查询，比如查看某数据类型的元素个数，时间复杂度是O(1)，因为数据结构本身就有记录了。

# 与Memcached的区别

* Redis支持存储多种数据类型：string、list、hash、set、zset；而Memcached只支持string

* Redis支持持久化：RDB快照和AOF日志；Memcached不支持持久化

* Redis支持事务，使用MULTI 和 EXEC命令，支持流水线式发送命令 ；Memcahced不支持事务，命令只能一条一条的发，当然这里的事务并不满足传统意义上的ACID

* Redis-Cluster 支持分布式存储，可以多台Redis服务器存储同样的数据；Memcached是以**一致性哈希算法**实现分布式存储，即多台Memcached服务器，Memcached根据查找的key计算出该数据在哪台服务器上

* 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘； 

  Memcached 的数据则会一直在内存中，Memcached使用固定空间分配，将内存分为一组大小不同的slab_class，每个slab_class又分为一组大小相同的slab，每个slab又包含一组大小相同的chunk，根据数据大小，放到不同的chunk里，这种管理方式避免内存碎片管理问题，但是会带来内存浪费，即每个chunk内会放小于这个chunk大小的数据，chunk里有些空间没利用到

  一致性哈希算法：构造一个长度为2的32次方的整数环，根据结点名称的Hash值([0，2^32-1])，将结点放置在这个Hash环上，根据数据的key值计算Hash值，在Hash环上顺时针查找距离这个Key的Hash值最近的结点，完成key到结点的Hash映射查找，这样当扩容结点时，只会影响到其中一个结点；为了解决负载不均衡问题，可以在此基础上增加一个虚拟层，key先在环上找到虚拟结点，再找到物理结点，将数据分散到各个结点，一般一个物理结点对应150个虚拟结点

# Redis的单线程

Redis的单线程，指的是网络IO和键值对读写由一个线程来完成，其他的如持久化、异步删除、集群数据同步都有额外的线程完成。

## 原理

Redis单线程之所以能处理得很快，得益于高效的数据结构，且也采用了**多路复用机制**，在网络IO操作中能并发处理大量客户端请求。监听 + 事件驱动 + 回调 的方式，处理易阻塞的accept和recv事件。

[一文揭秘单线程的Redis为什么这么快?](https://zhuanlan.zhihu.com/p/57089960?utm_source=wechat_session&utm_medium=social&utm_oi=632939468966072320)

总结一下就是：高效的数据结构和数据压缩、纯内存操作、非阻塞IO多路复用，避免频繁的上下文切换。

## 影响性能的场景

* 对big key的操作，比如创建和删除，big key在分配内存和释放内存会比较耗时。big key意味着value很大，当进行全量查询返回、聚合操作、全量删除(因为要释放内存)时可能会阻塞主线程。

  一般可以配合scan命令以及对应数据类型的scan命令来增量获取或删除。

* 一些命令对应的操作时间复杂度高，比如范围查询、keys命令。

  一般使用scan代替keys命令，scan命令时因为使用高位进位法遍历，所以即使在扩容情况下也不会漏key，但在缩容时可能得到重复的key。

* 大量Key集中过期，Redis过期机制也在主线程中执行，大量Key集中过期会导致耗时过长，所以在设置过期时间时要加入随机数。

* 淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰Key，也会产生耗时。

* 主从全量同步生产RDB快照，虽然采用fork子进程生成数据快照，但fork瞬间也会阻塞线程，另外，从库在接收RDB快照后，会清空所有键值对，如果量大的话也很耗时，如果RDB文件太大，加载也耗时。

* AOF日志同步写，因为是需要写磁盘的，比如设置为everysec可能会阻塞主线程。

* 切片集群，向其他实例传输哈希槽信息，bigkey数据的迁移。

改进的话，就只有删除操作和AOF日志同步写可以放在异步线程去做，Redis4.0以后才提供删除和AOF同步写的异步命令。

# 过期时间和数据淘汰策略

## key过期删除原理

* 定期删除策略：Redis起定时器扫描key（默认100ms），判断key是否过期，过期则删除。虽然可以保证过期的key会被删除，但是每次都要扫描会非常消耗CPU资源，且定时器有间距，有可能出现key过期，但是此时定时器还没起，key仍保存在内存中

* 惰性删除策略：每次获取key的时候才判断key是否过期，过期则删除，但如果key一直未被使用，则会一直留在内存里，浪费空间。

  注意在Redis3.2以前，主库惰性删除后，从库不会触发数据删除，此时还能读到，3.2以后的版本才改正，返回空值，4.0后从库才会定时校验过期key。另外，expire命令在主库设置key的过期时间，到了从库可能有延迟导致过期时间比实际的长，expire命令表示执行完多久会过期，expireat/pexpireat命令表示在某一时间点会过期。

* 所以Redis会将这两种策略整合在一起，定期删除策略不在是每次都扫描全部key，而是随机抽取一部分key进行检查，在配合惰性删除策略，正好可以弥补惰性删除策略的缺点

## 淘汰策略

当内存使用量超出所设置的maxmemory值时，才会执行淘汰策略。默认的淘汰策略是当内存满了之后，新写入操作会报错。maxmemory值一般设置为总数据量的15%-30%。

其他淘汰策略，分为两种，一种是在所有数据范围内，一种是在设置了过期时间的范围内。

* allkeys-random：在所有key中，随机移除某个key
* allkeys-Lru：在所有key中，移除最近最少使用的key（**优先使用**）
* allkeys-Lfu：在所有key中，移除访问次数最少的某个key
* volatile-random：在所有有设置过期时间的key中，随机移除某个key
* volatile-Lru：在所有有设置过期时间的key中，移除最近最少使用的key
* volatile-ttl：在所有有设置过期时间的key中，有更早过期时间的key优先移除
* volatile-Lfu：在所有有设置过期时间的key中，移除访问次数最少的某个key

### 淘汰策略中的LRU算法

对于LRU算法，如果一些元素被频繁使用，会导致频繁的移动，带来了额外的开销。

Redis的LRU算法做了简化，其只会在RedisObject中记录每个数据最近以此访问的时间戳，当出现数据淘汰时，第一次会*随机*选出N个数据，作为一个候选集合，比较N个数据的lru字段，把lru字段最小的元素淘汰。

再次淘汰时，Redis会挑选*那些*LRU的值小于候选集合中最小LRU值的数据，进入第一次淘汰时创建的候选集合，可能会把里面最大的换出去或者淘汰里面最小的。准备候选集和淘汰数据是两个解耦操作。

N的值由maxmemory-samples决定。

### 淘汰策略中的LFU算法

Redis的LRU算法有个问题是对于非热点数据，其访问次数很少，直到触发淘汰策略才会被删除，在被删除之前都会一直留存，造成缓存污染。LFU算法就是为了解决这个问题。

LFU缓存策略是在LRU策略基础上，为每个数据增加一个计数器，统计数据访问次数。当使用LFU淘汰策略筛选淘汰数据时，首先会根据访问次数进行筛选，把访问次数最低的数据淘汰出缓存，当淘汰次数相同时，才会比较时间。

LFU在LRU的基础上，将RedisObject中的访问时间戳拆成两半，16bit存时间，8bit存计数，但计数不是线性递增，而是采用一种计算规则，让其增长不那么快到达2^8=255次，同时也有衰减机制，减少次数对时间的影响。

# 存储与持久化

## RDB快照（Redis DataBase）

RDB快照由于保存的是数据，恢复起来会比AOF快（AOF保存的是命令），而且AOF是文本文件，RDB是二进制文件，所以RDB快照在网络传输、IO效率都比AOF好。

### 原理

将Redis中的数据全量保存的文件中，一般会使用子进程进行刷盘操作，不阻塞主线程，此时主线程仍然能处理命令。（**先全量**）

此外，会使用**Copy on Write机制（写时复制）**，解决创建快照的过程中，原有数据被修改对RDB快照的影响。当主线程对原有数据进行修改前，这块数据会被复制一份（复制引用，由bgsave子进程操作），形成副本（此时会消耗两倍内存），由子进程将该副本写入RDB文件中，由于写的是引用，主线程修改后会同步到RDB中。（**后增量**）

### 相关命令

bgsave，会调子进程创建快照写入磁盘，主线程继续处理其他命令请求

save，主线程创建快照写入磁盘，会阻塞其他命令请求

redis.conf配置里，save [时间] [次数] 表示在[时间]内有[次数]写入，就会触发bgsave命令

另外，在进行主从复制，主redis发生sync命令给从redis时，如果刚刚没有执行完bgsave，也会进行一次bgsave操作。

### 潜在风险

* 风险在于快照的创建频率，如果频繁创建快照，多快照写盘会影响磁盘IO，因此每次都进行全量快照并不可取。
* **如果频率过低，则会导致宕机时丢失的数据过多。解决方式是RDB + AOF一起使用，在两次快照期间用AOF代替。**
* 当使用copy on write机制时，主线程会为其申请额外的空间，当进行频繁的写操作时，会导致内存很快被耗光。当实例系统开启了Swap机制时，超过内存使用量部分会转移到磁盘，访问磁盘的那部分就会很慢，如果没有开启Swap机制，则会触发OOM，Redis进程可能被kill或宕机
* 另外，当出现频繁的写操作时，由于生成RDB的子进程需要CPU核运行，主线程、多个线程或后台进程会竞争使用CPU，导致性能降低。

## AOF（Append Only File）

## AOF配置项

* no：每次命令只写内存(日志缓冲区)，刷盘记日志的操作由操作系统决定

* everysec（默认）：写命令记录到文件中，**默认是每秒同步一次**，所以如果发生故障，最多会丢失一秒的数据，但使用AOF保存的数据文件比RDB快照要大。

* always：此外AOF还能选择每接收一个写命令就追加写入到AOF文件中，虽然能避免不丢数据，但每个写命令都是在主线程上完成，且后面都跟着一个刷盘操作，对机器的负担较大，影响服务性能。

### 原理

不同与MySQL的WAL机制，AOF是先执行命令将数据写入内存，再写入日志。因为AOF会记录Redis收到的每一条命令，并以文本的形式保存，如果先写日志，并不知道命令是否是正确的，因此先写内存，让系统执行成功后，才会记录到日志中，避免错误命令。

### 潜在风险

* 执行完命令，还没来得及记录日志就宕机，此时会丢失该命令的记录和相应数据。如果使用Redis当缓存，且要保证Redis宕机时不直接读库，利用Redis的AOF机制时就要注意了。
* AOF是在命令执行后才记录日志，所以不会阻塞当前的写操作，但由于日志的写操作也是在主线程中的，虽然避免阻塞当前操作，但可能会阻塞下一个命令操作，比如刷盘时磁盘IO过慢。

### 重写机制

一般用于**避免AOF日志文件过大**，毕竟如果文件太大会影响磁盘IO、重放会太耗时。

#### 原理

AOF重写机制在重写时，Redis根据Redis现状创建一个新的AOF文件，读取Redis中所有键值对后进行写入，但在重写时不是原样copy，而是会对命令进行合并，以此减小文件大小。

重写时，主线程会fork后台的bgrewriteiaof子进程，把**主线程的内存拷贝一份给bgrewriteiaof子进程**，其中也包括了Redis的最新数据，bgrewriteiaof子进程逐一写入重写日志，避免阻塞主线程。

因为重写是在子进程中处理的，此时主线程仍然能处理客户端的命令，当接收到客户端的写命令时，**会记录到AOF日志**中，**同时**也会写进**AOF重写日志**的缓冲区，等子进程将拷贝数据写完后，再把缓冲区的数据刷入，完成后即可删除AOF文件，留下AOF重写文件。

#### 潜在风险

* 主线程fork创建bgrewriteaof子进程时，内核会把主线程的PCB内容拷贝给子进程，此时会阻塞主线程，当要拷贝的内容特别大时，fork执行的时间就会变长，阻塞主线程的时间也会变长。
* bgrewriteaof子进程会和主线程共享内存，当主线程收到新增或修改操作时，主线程会申请新的内存空间用来保存，但是如果是bigkey，主线程就会面临申请空间过大导致耗时。

# 高可用集群

RDB和AOF保证了数据少丢失，集群部署保证服务少中断，实现高可用。

## 主从复制 - 保证数据一致性

一般采用主从读写分离，主服务器进行写操作，然后再同步给从服务；而读操作发生在主从服务器均可。最好还是读写都在主库，从库只保证高可用，原因是主从数据同步是异步的，总有可能出现网络波动等问题导致主从库数据不一致，或者主库设置过期时间，但是到从库上有延迟导致读到过期数据，主库的过期删除无法同步到从库（4.0才解决）。

如果写操作可以发生在主从服务器上，会导致主从服务器上的数据不一致，取数据时可能会取到旧值，而如果要保持一致，则需要加锁，加锁的话效率旧太差了。

一般用在**从节点**初始化加入时使用，先进行**全量同步(通过快照)**，再进行**增量同步(通过命令缓存同步)**。

### 相关命令

在从库上使用命令：Redis 5.0以前使用slaveof、之后使用replicaof  [主库IP] [主库端口]

### 过程

1. 主服务器创建RDB快照文件，发送给从服务器，并在发送期间使用缓冲区(replication buffer)记录之后收到的写命令。

   快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；整个过程中主服务器不会被阻塞。

2. 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；

3. 主服务器每执行一次写命令，就向从服务器发送相同的写命令

一般只设置一个主节点，当负载上升时，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。

解决办法：通过主从级联模式解决，可以设置主节点为根节点，向下延申，从节点再设置从节点的方式，形成树状的主从链，让从节点帮忙同步给其子节点的方式，降低主节点的压力。

同样使用命令slaveof或replicaof，只是ip换成从库的ip，这样就形成了主-从-从的模式了

## 主从库命令传播时网络中断

Redis2.8之前，如果主从库发生网络中断，重写连接时会进行全量复制，开销巨大。

2.8之后，会使用增量复制。断连期间，主库会把收到的写命令写入缓冲区(replication buffer和repl_backlog_buffer)。repl_backlog_buffer是一个环形缓冲区，主库会记录自己写到的偏移量(master_repl_offset)，从库会记录自己读到的偏移量(slave_repl_offset)。

断连时，会记录从库的偏移量，待重新连接后即可根据偏移量进行同步。由于repl_backlog_buffer是环形缓冲区，如果从库同步太慢，因此可能会出现新命令覆盖到未读取的命令，只能通过调整其大小解决，配置repl_backlog_size，否则，从库将进行全量复制。

主从模式下，从库宕机影响不大，但主库宕机就会影响从库的同步了，此时需要哨兵机制重新选举主库，保证高可用。

**replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，非共享，每个从库对应一个**

**repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer，从库共享，只是每个从库都会有复制进度标志(slave_repl_offset)记录在上面**

## 哨兵机制

哨兵机制会解决三个问题：1.判断主库是否宕机 2.选择哪个从库为主库 3.如何把新主库的信息通知给从库和客户端。

使用**哨兵模式**（sentinel）来监听和管理Redis集群，存储集群配置，作用类似ZooKeeper，哨兵节点是一台特殊的Redis，功能有限，主要用来支持哨兵机制，哨兵节点有三个任务：监控、选主、通知。

### 原理

**哨兵节点一般设置3个及以上的奇数个，哨兵节点间是平级的，会互相监控**。

* 所有哨兵节点都会周期性的给所有主从库发送Ping命令检测Redis的主从节点是否正常运行，当有Redis节点出现问题时，进行通知。
* 如果发生问题的节点是主节点，会从从节点中选出主节点，代替失效的主节点。
* 之后会把新主库的连接信息发给其他从库，让他们执行replicaof命令，和主库建立连接，并进行数据复制。同时把新主库的连接信息通知给客户端，让客户端把请求发送到新主库上。

### 如何监控，如何判断主库不可用

**主观下线**：每个哨兵节点每隔1s对主从节点发生心跳，当有节点再超过x秒后没有进行回复，此时该节点为主观下线，还需要进一步判断。

**客观下线**：当主观下线的节点是主节点时，该哨兵节点会通过`sentinel is-master-down-by-addr`命令，向其它n-1个哨兵节点询问对主节点的判断，当超过 n / 2 + 1 个哨兵节点认为主节点有问题时，该节点为客观下线。**多这一步是为了防止误判。**

客观下线后，会从从节点中选举出主节点，前主节点重新上线后会被设置为从节点

Redis没有使用什么一致性算法，仅依据**Gossip协议**在有效时间范围内收到其它Sentinel节点的确认。

另外，如果不使用哨兵模式，只使用Redis集群，也可以实现高可用，只不过是把监控和选择转移到各个节点中。

### 如何选举

哨兵节点会周期性的发送心跳给主从库，在此过程中会对各个节点进行打分。之后按照一定的筛选条件和规则，选出得分最高的从库为新主库。

* 筛选条件：从库的在线状态，之前的网络连接状态。通过设置主从库断连的最大连接超时时间（down-after-milliseconds）、断连次数（n），当超过阈值时则说明从库的网络状况不好。
* 打分规则：从库的优先级（比如不同从库的配置不一样，优先级也就不一样）、从库的复制进度（根据从库在repl_backlog_buffer中的偏移量，从库间比较）、从库的ID号（ID号小的分高）

### 如何通知

客户端在访问主从库时，不能写死主库地址，而是从哨兵节点中获取主库地址；当哨兵选出新的主库时，会更新自己存的新主库地址。哨兵节点通过 发布/订阅 机制，让客户端进行订阅和修改。从而也能让客户端了解整个主从切换过程。

### 主从切换时，可能产生脑裂

如果主库因为某些原因进入假死状态（但还能处理命令），被哨兵判定为客观下线，哨兵执行主从切换，但此时主库恢复正常，但此期间写操作的数据还未同步到从库，待哨兵完成主从切换后，Redis集群会短暂出现两个主库，导致客户端的写操作会发往不同的主库，或者原主库降级成从库，会清空本地数据重新载入新主库的RDB快照，导致数据不一致或丢失。

解决方法：在主库上配置`min-slaves-to-write`表示主库能进行数据同步的最少从库数量；`min-slaves-max-lag`表示主从数据复制时，从库给主库发送ACK消息的最大延迟(秒)。这样当主库假死时，无法响应哨兵心跳，也不能和从库同步，确认从库的ACK命令，原主库就无法再接收客户端的写操作。

另外一种脑裂是，主库和客户端，哨兵和从库被分割成两个网络，此时哨兵与从库的网络里，哨兵会重新选出主库，但旧主库仍然能处理客户端写操作，网络恢复后，主库降级，数据丢失。

根本原因：Redis主从集群没有使用共识算法，每个写操作没有在大多数节点写成功后才认为成功导致的。不像ZooKeeper，客户端的操作都会经过ZooKeeper的主节点，当发生脑裂时，ZooKeeper主节点无法写入大多数节点，写请求直接失败，保证数据一致性。

### 哨兵集群的高可用

由于哨兵需要进行客观下线的判断，因此需要多个哨兵组成集群，集群就会涉及到高可用。

#### 哨兵节点间、与主从库间的相互发现机制

**哨兵节点间的相互发现**：正常情况下，每个哨兵都是平级的。每个哨兵节点在设置时的命令是`sentinel monitor <master-name> <ip> <redis-port> <quorum> `，并不感知其他哨兵的存在。**哨兵节点间的相互发现，以来Redis的 发布/订阅 机制**。哨兵节点一旦和主库建立连接，就会把自己的连接信息(如IP、端口)发布到主库上，同时它也会订阅，从而发现其他哨兵节点。

**哨兵节点发现从库：**哨兵节点连接主库后，发送INFO命令，主库就会把从库连接信息列表发给哨兵节点，从而实现哨兵节点对从库的监控。

#### 哨兵节点Leader选举原理

正常情况下哨兵集群内的每个哨兵节点是平级的，但是当触发客观下线时，需要选出一个哨兵节点Leader来执行主从库切换。重新选举主库只能由一个哨兵节点来做，如果不是，可能会出现主从库集群脑裂。另外，哨兵节点越多，选举速度越慢，风险也会增加。

哨兵节点Leader选举分为两个阶段

1. 各个哨兵节点判断主/客观下线阶段：各个哨兵在判断主库是主观下线后，首先会给自己投Yes票，之后会发送`is-master-down-by-addr`命令给其他哨兵节点，其他哨兵节点会根据自己的判断情况，回复Yes / No回去。该哨兵节点收集得到的Yes票，当超过设置的quorum值时，标记主库为客观下线。

2. 每个哨兵在一次选举节点只有一次投票机会，当有哨兵节点得出客观下线结论后，该哨兵再发起投票，进行Leader选举，当收集到的票数超过一半，则该哨兵节点成为Leader节点，如果没有选举成功，则等待一般是故障转移超时时间failover_timeout的2倍时间后会从新举行选举。

![Redis哨兵下线主库和Leader选举](https://github.com/Nixum/Java-Note/raw/master/picture/Redis哨兵下线主库和Leader选举.png)

# 高可扩展集群 

一般一个Redis保存几个G内比较合适，**当单个Redis实例要保存的键值对太多时，会影响Redis的主从复制、RDB快照和AOF日志的大小、影响从库重放速度、fork子进程的速度(太慢会导致阻塞主线程)**，因此需要进行对单Redis实例扩展，常见的方式是对单个Redis实例进行扩展，一般分为纵向扩展和横向扩展。

## 扩展

* 纵向扩展：升级单Redis实例的配置，如内存容量、磁盘容量、CPU等，但会影响RDB快照和AOF日志大小，网络传输等，一般用在不使用Redis持久化功能的场景。
* 横向扩展：根据key，对Redis实例进行分片，增加Redis实例个数。

## 分片

### 原理

* 将数据分散到集群的多个机器上，Redis里使用的概念是槽Slot，每个集群的槽数固定为16 * 1024 = 16384个，使用哈希分片算法对Key进行取模，计算方法：`HASH_SLOT = CRC16(Key) mod 16384`，余数为Key所在的槽。

  之所以会使用槽，是因为要把数据和节点解耦，如果不使用槽，而是使用key与节点的映射表，当key的数量非常庞大时，映射表也会非常大，映射表的修改和迁移的性能不高。

* 集群内每台机器会存放一些槽，在集群初始化的时候会对集群内的机器**平均分配这16384个槽**，使用查表法进行分配。因此，当需要扩容时，会重新计算槽的位置和迁移key，可以使用官方提供的redis-trib.rb脚本实现。

* 客户端连接分片集群后，即可获得槽与各个Redis分片节点的映射。访问时可以访问集群内的任意节点，先根据key算出在哪个槽，在查询槽和节点间的关系，找到对应的节点进行查询。

  另外，要注意分片后，对于Keys、scan这样的扫描命令的性能就会更加差了。

* 当分片集群有增删时，槽与节点的映射也会随之修改，为了负载均衡，Redis需要把槽重新分布到各个分片上。但是客户端却不感知，当客户端发送命令时，如果节点上该槽已迁往别处，客户端会收到`MOVED 新槽编号 新槽所在的host`的错误信息，客户端将重新请求，同时修改槽与节点的映射关系。

* 如果客户端请求发生在Redis迁移槽的过程中，则会先收到`ASK 新槽编号 新槽所在的host`的错误消息，让客户端进行重试，直到Redis完成槽的迁移，重试成功。

* HashTag，如果key的格式是 user:order:{3214}，由{}括起来的部分为HashTag，CRC算法在计算key在哪个槽时只会计算{}里的值，HashTag主要是让多个类型的key可以映射到同一个槽，方便范围查询。

  但使用HashTag可能会导致数据倾斜，使得请求无法平均分到各个分片。

一般的分配规模是几十个以内，不适合构建超大规模的集群，原因是去中心化设计，选举算法使用Gossip，规模越大时，插播速度越慢。如果要构建超大规模的集群，则需要增加一层代理，进行集群间的转发，例如twemproxy或者Codis这类基于代理的集群架构。

# 事务

使用 MULTI 和 EXEC 命令将多个写操作包围起来进行发送，Redis收到后会先将命令暂存到一个队列里，当收到EXEC命令时才会一起顺序执行。

## Redis中的原子性

* 更多的是为了减少客户端与服务端的通信次数。Redis本身不提供回滚机制，如果一次性传输多个命令时，当有一个命令执行失败了，剩下的命令还是会继续往下执行，无法实现事务的原子性。
* 如果命令本身有错，只有到了EXEC命令时才会保错，整个MULTI期间的命令都不会执行，此时才保证了原子性。
* RDB不会在事务执行的时候执行，所以可以保证原子性。
* 事务执行过程中的命令，AOF日志则会记录，所以如果事务执行过程中宕机了，重启前需要使用redis-check-aof工具检查AOF日志，去除执行到一半的事务命令，才能保证原子性。

### Redis中的原子操作

* Redis的 incr / decr 命令，本质上是一个读取 -》修改 -》写入的过程
* 为Redis定义新的数据结构实现原子操作，毕竟Redis本身是单线程的，本身不会有其他线程的影响。
* Lua脚本，才能实现复杂逻辑的原子操作，使用时会先通过script load命令把脚本加载到Redis中，得到唯一摘要，再通过命令evalsha + 摘要的方式执行脚本，避免每次执行脚本都要先传输，减少网络IO；另外Lua脚本的时间复杂度不易过长，否则会阻塞主线。

Demo：限制客户端每分钟访问次数不能超过20次 的Lua脚本，该脚本包含了计数、访问次数判断和过期时间设置。

```lua
// 客户端先获取ip对应的访问次数
current = redis.call("get", KEYS[1])
//如果超过访问次数超过20次，则报错，这两步不涉及临界值的修改，因此可以不放在脚本中原子执行。
IF current != NULL AND current > 20 THEN
    ERROR "exceed 20 accesses per second"

Lua脚本名称：visit_restrict.script
脚本内容
    //如果访问次数不足20次，增加一次访问计数
    value = redis.call("incr", KEYS[1])
    //如果是第一次访问，将键值对的过期时间设置为60s后
    IF value == 1 THEN
        redis.call("expire", KEYS[1], 60)
    END
    //执行其他操作
    DO THINGS
END
执行命令：
redis-cli --eval visit_restrict.script keys , args
```

## Redis中的隔离性

* 需要依赖Watch机制，因为Redis流水线命令是在Exec命令执行后开始的，在Exec命令还未执行前，如果要保证隔离性，需要使用Watch监控某个key，当Exec命令执行时，Watch机制就会触发，如果监控的数据被修改了，就放弃此次事务的执行。
* 如果是在Exec命令执行后的，由于Redis是单线程的，所以并发情况下不会破坏事务隔离性。

## Redis中的一致性

在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的。

## Redis中的持久性

尽管有RDB和AOF日志的支持，但是仍然有丢数据的可能。比如使用RDB模式，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，此时，事务修改的数据也是不能保证持久化的。

# 应用场景

## 聚合统计 - 统计每日新增用户

* 使用Set类型
* 一个Set记录所有登录过的用户ID：[key：user:id，value：Set<userId>]，另一个Set记录每日登录过的用户ID[key：user:id :日期，value：Set<userId>]
* 统计每日新增用户，计算每日用户 Set 和累计用户 Set 的差集，使用命令`SDIFFSTORE [结果key] [user:id :日期] [user:id]` 
* 弊端：Set的差集、并集、交集计算复杂度较高，当数据量较大时计算太慢会阻塞主线程，一般这种计算会在从库上做。

## 排序统计 - 统计最新评论、排行榜、时间段内在线数等

* 使用List，当有新元素LPush或RPush插入时，原先所有元素都会后移一位，使用Lrange读取元素时可能会读到旧数据。
* 使用ZSet，为每个元素设置权重，按权重排序，使用Zrangebyscore则不会读到旧数据。

## 二值状态统计 - 统计是否签到、存不存在、有没有问题

* 针对值只有0 或1的场景，使用bitmap，是Redis的扩展数据类型，本身是String类型的一种特殊应用。
* bitmap利用的是存储的String value的位。并且bitmap支持Bitop命令对多个bitmap进行按位与、或、异或操作，bitcount统计位中1的个数。

## 基数统计 - 统计一个集合中不重复的元素

* 使用Set或Hash，但是可能会比较耗内存
* 使用HyperLogLog，专门用于基数统计，优势在于所需空间总是固定，使用`PFAdd key v1 v2 v3`命令做添加，`PFCount key`统计key的value数量，但是存在误差，误差率约为0.81%

## GEO - LBS应用

* 底层实现是ZSet，权重值是经纬度，但是由于ZSet的权重值只能是浮点类型，因此一般会对经纬度做GeoHash编码。
* GeoHash编码的基本原理是：二分区间，区间编码。
  * 二分区间：比如把经度范围[-180,180]会被分成两个子区间：[-180,0) 和[0,180]，如果要编码的经度值落在左区间，则用0表示，右区间用1表示，通过不断的对区间进行分区，经过N次之后，得到一个N位数的01组合。纬度同理。
  * 区间编码：把经纬度编码进行组合，规则：偶数位是经度编码值，奇数位是纬度编码值。
* 通过GeoHash编码，地图上的每个方格都能用数字进行表示，分区越多越精准。**通过范围查询 + 方格周围方格的编码，即可实现搜索附近的人功能**。
* Redis也提供了Geo的数据类型

## 保存时间序列数据

* 时间序列数据的特点是插入速度要快，数据一旦插入就不变、查询模式较多。
* 可以基于Hash和ZSet实现。Hash实现插入快速和点查询，ZSet实现范围查询，但由于插入一条数据的时候需要同时操作Hash和ZSet，因此要求这个操作是原子的。
* ZSet只能提供范围查询，聚合查询只能在让客户端查回去之后自己做，但是大量数据查询传输比较依赖网络资源，可能会导致其他操作响应速度变慢，如果想要Redis实现的话，就得依靠RedisTimeSeries。

## 消息队列

* 消息队列一般要解决三个问题：顺序消费、幂等消费、消息可靠性保证

* 使用List

  * List的每个元素除了消息的内容外还要保存消息的唯一id，用于解决重复性消费；
  * List类型有提供BRPOP供消费者阻塞读取，避免循环读取带来的消耗；
  * List类型有提供BRPOPLPUSH命令，让消费者读取时会把数据存入另一备份List中，用于避免消费者从List中移除消息读取时宕机，重启后可重新读取消息。
  * List不支持消费组实现，无法避免生产速度大于消费速度的场景。

* 使用Stream类型，解决多端消费问题。

  * Stream的XADD命令，可以为其生成全局唯一ID。
* 读取时使用命令XRead，可支持指定ID读取，也支持超时阻塞读取。
  * 命令XGroup创建消费组，XREADGROUP指定组内哪个消费者进行消费。
* Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令进行回复。如果消费不成功，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。当消费者重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。
  
  * Stream是Redis5.0以后才有的专门用来处理消息队列的。

# 缓存可能引发的问题以及应对方法

使用Redis来构建缓存有两种模式

* 只读缓存：加速读请求。应用读取数据，先向Redis查询，查不到再查库，然后保存到缓存中。应用写数据，先改库，删掉旧缓存数据。这种方式可以很好的保证了一致性。
* 读写缓存：同时加速读写请求。读写都会在缓存里发生，最新的数据是在Redis中，但需要严重依赖Redis的持久化。这种方式对一致性的保证就差了点，特别是在高并发下。
  * 同步直写：优先保证数据可靠。写请求会同时修改缓存和库，等到都完成了才返回，需要保证原子性。
  * 异步写回：优先保证快速响应。写请求会先在缓存中处理，等到这些增改数据要从缓存中淘汰，才会写回数据库。

## 缓存雪崩

现象：缓存大面积失效导致请求到达数据库

应对方案：

* 缓存过期时间设置均匀，不能让一大片缓存在某一时间全部失效，比如设置过期时间时加入随机数，让过期时间在一个范围内波动。

* 请求时加锁(比如利用redission的rlock)，后续请求只能等到前面的查完数据库，进行缓存后，才能继续，但会造成吞吐量降低，响应时间变长，或者可以使用semaphore设置一定的信号量，不至于只有一个请求去回源数据库。
* 不设置key的过期时间，另开一个定时任务定期全量更新缓存；或者定时任务定期扫描，将快要过期的key延迟过期时间；设置多级缓存。
* 灰度发布，对缓存进行预热。
* 服务降级，当访问的数据是非核心数据，直接返回预定义数据或空值；当访问的数据是核心数据，仍允许查缓存，查库。
* 如果是Redis实例发生宕机，只能在应用层中实现服务熔断或请求限流。

## 缓存击穿

现象：访问非常频繁的热点数据过期

应对方案：不给热点数据设置过期时间，一直保留。

## 缓存穿透

现象：查询一个一定不存在的数据，导致请求一直到达数据库，数据也不在数据库中。

应对方案：

* 使用布隆过滤器，将可能出现查询的值哈希到一个bitMap中，进行拦截，虽然布隆过滤有一定的误报几率，但也能一定程度的减少穿透的影响，常见的方案是配合2一起降低穿透带来的影响。
* 如果查询结果为空，也加入缓存中（可以直接设置为空，或者使用特殊标识来表示），并设置过期时间。
* 通过异步更新服务 + 消息队列的方式进行全量缓存的更新。缓存的设置还是照旧，只是当有数据更新时，只是触发消息交给消息队列，再由异步更新服务消费消息，实现缓存更新。
* 利用数据库的Bin Log，当数据库执行更新操作时，从数据库接收到Bin Log之后根据Bin Log更新Redis缓存，道理跟消息队列类似，只是不用担心消息发生失败问题。
* 前端预防，对请求进行检测。

## 缓存无底洞

现象：增加缓存节点，性能不升反降，原因是客户端要维护大量的连接，如果key分布在不同机器，需要查多次

应对方案：

* 减少网络请求，能批量查尽量批量查
* 将key进行分类，存到指定节点，查询同类的key时只需要特定的节点去查
* 并发查询

## 缓存污染

现象：对于那些访问次数很少的数据，一直留存在缓存中，占用缓存空间。

应对方案：Redis的淘汰策略，一般会使用LRU、LFU、TTL的淘汰策略。

## 主动更新缓存要注意的点

1. 不推荐先更新缓存再更新数据库，原因是数据库操作可能失败，导致缓存与数据库不一致；
2. 不推荐先更新数据库再更新缓存，原因是两者更新数据的顺序可能不一致，更新到缓存的数据也不一定被访问；
3. 不推荐先删缓存再更新数据库，访问时再进行加载，原因是并发情况下，删除缓存后来不及更新数据库，但旧值已经被其他线程读到了，更新到缓存了；或者数据库操作失败了，但缓存已经没了，导致其他请求还要再读一次数据库；应对的方案是延迟双删，先删缓存 -》更新数据库 -》sleep -》再删除缓存
3. 推荐先更新数据库再删除缓存，访问时再进行加载（也称为cache aside模式），虽然也可能出现3中的情况，导致数据不一致，但带来的影响会相对小一些，如果删除缓存失败了，可以延迟任务进行删除重试，因为删除操作一般是幂等的，所以即使重复删除也没关系，另外，相比Read/Write Through模式（更新数据库后更新缓存操作），不会因为并发读写产生脏数据。还有由于会删除缓存，所以要注意缓存穿透问题。

![Redis缓存方案操作 - 极客时间Redis核心技术与实战](https://github.com/Nixum/Java-Note/raw/master/picture/Redis缓存方案操作.png)

# 使用规范

* String类型的数据不要超过10KB，避免BigKey
* Key的长度尽量短
* key的过期时间加上随机值，避免key的集中过期
* 集合类型的元素个数不超过一万个
* Redis实例容量控制在10GB内
* 禁用Keys、FlushAll、FlushDB命令，慎用全量操作命令、Monitor命令、复杂度过高的命令（如Sort、Sinter、SinterStore、ZUnionStore、ZInterStore）

# 参考

极客时间 - Redis核心技术与实战：讲得很不错，推荐。

还有其他看过的别人博客，但是当时忘记把链接贴下来。