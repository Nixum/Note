[TOC]

# 使用场景

* 秒杀系统，一般秒杀系统处理包含几个步骤：风险控制、库存锁定、生成订单、短信通知、更新统计数据灯，而决定秒杀是否成功只在前两个步骤，后续的操作就可以通过消息队列**异步**处理完成，加快整个流程的处理，**减少等待时间，提升并发量**。
* 隔离网关和后端服务，实现**流量控制，保护**后端服务，但会增加系统调用链，导致总体响应变长，异步增加系统复杂性。
* 令牌桶，目的也是进行流量控制。
* 服务解耦，数据同步，比如订单系统在订单状态发生变化时发出消息通知，其他服务订阅后做相应处理。
* 连接流计算任务和数据，比如集群日志处理，大数据统计
* 将消息广播给其他接收者

## 好处

流量削峰和流量控制、异步处理、解耦、广播、最终一致性

## 缺点

可用性降低、复杂度提高、一致性问题、消息延迟

# 常见消息队列

| 特性                    | ActiveMQ                                                     | RabbitMQ                                                     | RocketMQ                                                     | Kafaka                                                       |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量              | 万级，吞吐量比RocketMQ和Kafka要低了一个数量级                | 万级，吞吐量比RocketMQ和Kafka要低了一个数量级                | 10万级，RocketMQ也是可以支撑高吞吐的一种MQ                   | 10万级别，这是kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic数量对吞吐量的影响 |                                                              | 使用队列模型，通过Exchange模块实现发布-订阅模型，Exchange位于生产者和队列之间，由Exchange决定将详细投递到哪个队列。 | topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic | topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源 |
| 可用性                  | 高，基于主从架构实现高可用性                                 | 高，基于主从架构实现高可用性                                 | 非常高，分布式架构                                           | 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性              | 有较低的概率丢失数据                                         |                                                              | 经过参数优化配置，可以做到0丢失                              | 经过参数优化配置，消息可以做到0丢失                          |
| 时效性                  | ms级                                                         | 微秒级，这是rabbitmq的一大特点，延迟是最低的                 | ms级                                                         | 延迟在ms级以内                                               |
| 功能支持                | MQ领域的功能极其完备                                         | 基于erlang开发，所以并发能力很强，性能极其好，延时很低       | MQ功能较为完善，还是分布式的，扩展性好                       | 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 |
| 优劣势总结              | 非常成熟，功能强大，在业内大量的公司以及项目中都有应用。偶尔会有较低概率丢失消息，而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用 | erlang语言开发，性能极其好，延时很低；吞吐量到万级；拥有灵活的路由配置；MQ功能比较完备而且开源提供的管理界面非常棒，用起来很好用；社区相对比较活跃；RabbitMQ确实吞吐量与其他几个相比会低一些，这是因为他做的实现机制比较重；对消息的堆积支持不是很好，当有大量消息积压时，会导致RabbitMQ性能急剧下降；erlang开发，比较小众，很难读源码，很难定制和掌控。 | 接口简单易用，日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景。java实现，源码易读；中文社区活跃度，文档相对来说简单，接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码。 | kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量。而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。异步批量操作性能极佳，但是同步收发信息因为要攒一批消息才进行处理会导致响应延时比较高。 |

# 消息模型

1.点对点：队列、监听器

2.发布订阅：监听器、监听器、观察者模式

## 一般消息队列架构

* 主要是设计中间的消息转发，将一次RPC转化成两次RPC；
* 选择通信协议；
* 消息的可靠性确认；
* 消息持久化；
* 消息模型；
* 事务特性；
* 分布式集群特性；
* 消息队列一般有两种模式，pull模式（消费方主动向队列拉取数据），比如kafka，push模式（由队列向消费方推送数据）

![消息队列架构](https://github.com/Nixum/Java-Note/raw/master/Note/picture/消息队列架构.png)

一般来说，一个主题可以分配给多个Broker，每个Broker可以有多个队列；

多个生产者对于同一个主题的消息，可以发送到不同的队列（轮询发，随机挑一个发，只往某个一个发）；

消费组订阅的是主题，消费主题里的所有队列的消息，消费消息时，可以只是去读队列里的消息，不一定会删掉；

多个消费组在消费同一主题时，消费组之间互不影响，即消息可以同时被多个消费组消费；

消费组内部可以包含多个消费者，同一消费组内，每个队列只能被一个消费者占用，一个消息只会被组内一个消费者消费；

每个消费组内部维护自己的消费位置，记录消费某一队列中消息的位置，消费位置与消费者无关

## 关于消息的序列化和反序列化

除了常见的json、XML、protobuf、Kryo、Hession等方案，还能自主设计

客户端和服务端维护一份字段顺序，在序列化时只存对应对象的值，从而减少序列化对象的长度，比如

```
03   | 08 7a 68 61 6e 67 73 61 6e | 17 | 01
User |    z h a n g s a n         | 23 | true
03表示对象类型，08表示名字的长度，然后字段值以名字、年龄、是否yi'wei
```

## 关于消息的断句

数据传输过程中，收到的分段不一定是发出去的分段，因此需要合理的分段，来让数据语义明确。比如在每个分段前加数据的长度

```
03下雨天 03留客天 02天留 03我不留
```

## 关于消息的存储



## 案例一 - 异步消息的处理

![](https://github.com/Nixum/Java-Note/raw/master/Note/picture/JD_JMQ消息接收线程模型.png)

> 1. 收到请求后，我们在Handler中不做过多的处理，执行必要的检查后，将请求放到一个内存队列中，也就是图中的RequestsQueue。请求被放入队列后，Handler的方法就结束了。可以看到，在Handler中只是把请求放到了队列中，没有太多的业务逻辑，这个执行过程是非常快的，所以即使是处理海量的请求，也不会过多的占用IO线程。
> 2. 由于要保证消息的有序性，整个流程的大部分过程是不能并发的，只能单线程执行。所以，接下来我们使用一个线程WriteThread从请求队列中按照顺序来获取请求，依次进行解析请求等其他的处理逻辑，最后将消息序列化并写入存储。序列化后的消息会被写入到一个内存缓存中，就是图中的JournalCache，等待后续的处理。
> 3. 执行到这里，一条一条的消息已经被转换成一个连续的字节流，每一条消息都在这个字节流中有一个全局唯一起止位置，也就是这条消息的Offset。后续的处理就不用关心字节流中的内容了，只要确保这个字节流能快速正确的被保存和复制就可以了。
> 4. 这里面还有一个工作需要完成，就是给生产者回响应，但在这一步，消息既没有落盘，也没有完成复制，还不能给客户端返回响应，所以我们把待返回的响应按照顺序放到一个内存的链表PendingCallbacks中，并记录每个请求中的消息对应的Offset。
> 5. 然后，我们有2个线程，FlushThread和ReplicationThread，这两个线程是并行执行的，分别负责批量异步进行刷盘和复制，刷盘和复制又分别是2个比较复杂的流程，我们暂时不展开讲。刷盘线程不停地将新写入JournalCache的字节流写到磁盘上，完成一批数据的刷盘，它就会更新一个刷盘位置的内存变量，确保这个刷盘位置之前数据都已经安全的写入磁盘中。复制线程的逻辑也是类似的，同样维护了一个复制位置的内存变量。
> 6. 最后，我们设计了一组专门用于发送响应的线程ReponseThreads，在刷盘位置或者复制位置更新后，去检查待返回的响应链表PendingCallbacks，根据QOS级别的设置（因为不同QOS基本对发送成功的定义不一样，有的设置需要消息写入磁盘才算成功，有的需要复制完成才算成功），将刷盘位置或者复制位置之前所有响应，以及已经超时的响应，利用这组线程ReponseThreads异步并行的发送给各个客户端。
> 7. 这样就完成了消息生产这个流程。整个流程中，除了JournalCache的加载和卸载需要对文件加锁以外，没有用到其他的锁。每个小流程都不会等待其他流程的共享资源，也就不用互相等待资源（没有数据需要处理时等待上游流程提供数据的情况除外），并且只要有数据就能第一时间处理。
> 8. 这个流程中，最核心的部分在于WriteThread执行处理的这个步骤，对每条消息进行处理的这些业务逻辑，都只能在WriteThread中单线程执行，虽然这里面干了很多的事儿，但是我们确保这些逻辑中，没有缓慢的磁盘和网络IO，也没有使用任何的锁来等待资源，全部都是内存操作，这样即使单线程可以非常快速地执行所有的业务逻辑。
>
> 这个里面有很重要的几点优化：
>
> 第一是使用异步设计，把刷盘和复制这两部分比较慢的操作从这个流程中分离出去异步执行；
>
> 第二是使用了一个写缓存JournalCache将一个写磁盘的操作，转换成了一个写内存的操作，来提升数据写入的性能，关于如何使用缓存，后面我会专门用一节课来讲；
>
> 第三是这个处理的全流程是近乎无锁的设计，避免了线程因为等待锁导致的阻塞；
>
> 第四是把回复响应这个需要等待资源的操作，也异步放到其他的线程中去执行。

## 案例二 - Kafka高性能IO

* Kafka的SDK，生产者调用SDK发送消息时，看起来只发了一条，但是SDK处理时不是一条一条发的，而是先把消息放到内存中缓存起来，攒一批，异步一块发给broker，broker会把这一批消息当成一条处理，消费者pull消息，也是一次性拉取这一批消息进行处理，从而减少Broker处理请求的次数，减轻压力。
* 顺序读写，Broker收到消息后，顺序写入对应的log文件，一个文件写满就开启新文件顺序写下去，消费时也是从log文件的某一位置开始，顺序的读出来
* 利用PageCache加速读写，数据写入文件时，先写入PageCache，再一批一批写入磁盘，读取文件时，也是先从PageCache中读取数据，当PageCache中没有数据，会引发os的缺页中断，读取先从会被阻塞，直到数据从文件中复制到PageCache，再从PageCache中读取数据。
* 零拷贝提升消费性能：一般来说，Broker处理消费时，会先从文件复制数据到PageCache，从PageCache复制数据到应用内存，从应用内存复制到Socket的缓冲区，发送数据。如果文件中的数据无需其他处理，可以使用零拷贝，直接将数据从PageCache复制到socket缓冲区，减少复制次数

# 常见问题

以下问题都是需要分具体的MQ的，这里简单说下通用方法。一般异常会出现的场景：

* 生产者：网络或内部问题导致消息发送失败，没发出去；或者是发出去了，但是没有接受成功响应导致重复发送。
* 消费者：消费者获取了消息，处理消息的过程中宕机，恢复时消息如何处理。
* 消息队列：宕机重启时会丢数据

## 如何利用事务消息实现分布式事务

以RocketMQ为例，生产者先发送一个半消息给MQ，此时的半消息对消费者不可见，完成之后执行本地事务，根据本地事务的执行结果，对刚刚发送的半消息进行commit或rollback，只有commit之后，消费者才能消费此消息。如果生产者本地事务提交成功后宕机，MQ会调用生产者提供的反查方法确认半消息的之后的执行状态，反查方法会有三个结果：提交、回滚、不确定，如果查询结果是不确定，MQ则会进行重试，直到查到确定的结果或者超重试次数。这种场景其实是默认消费者一定会消费成功的，如果要让消费者消费不成功时，生产者也回滚，那就不能用这种方案了。

## 如何保证高可用性

集群 + zookeeper + 负载均衡

以ActiveMQ为例（因为是主从架构）

使用ZooKeeper（集群）注册所有的ActiveMQ Broker。只有其中的一个Broker可以提供服务，被视为 Master，其他的 Broker 处于待机状态，被视为Slave。如果Master因故障而不能提供服务，Zookeeper会从Slave中选举出一个Broker充当Master。
Slave连接Master并同步他们的存储状态，Slave不接受客户端连接。所有的存储操作都将被复制到 连接至 Master的Slaves。如果Master挂了，得到了最新更新的Slave会成为 Master。故障节点在恢复后会重新加入到集群中并连接Master进入Slave模式

消息数据可以持久化或非持久化，在集群内共享，当有节点挂掉后，其他节点也可以通过这些共享的数据顶上。另外，也可通过定时任务定时对失败的消息进行补偿。

数据的持久化存储可以存储在文件系统 > 分布式KV > 分布式文件系统 > 数据库（速度上的排列，但可靠性就要反过来了）

## 如何解决消息重复问题，保证消息幂等性

消息幂等，可以保证即使消息被重复消费也无所谓，一般来讲，重复发送总是存在的，要避免的是即使重复消费也能保证业务正确。要保证消息重复发送，除非允许消息丢失

**常见实现幂等性方法**：

* 保证消息幂等一般是在消费者做，消费者处理消息的时候将消息入库记录，利用数据库的唯一键约束实现，比如通过消息id + redis/MySQL/Mongo来判重。
* 更新数据时设置前置条件，如果满足该条件则更新数据，否则拒绝更新数据，在更新数据的同时，变更前置条件中需要判断的数据，这样当重复执行这个操作时，由于第一次更新已经修改了前置条件，不满足前置条件时，则不会重复执行更新数据的操作，比如给数据增加一个版本号，每次更新数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时，版本号+1，实现幂等更新。
* 在发送消息时，给消息指定一个全局唯一的ID，消费时，先根据这个ID检查这条消息是否被消费过，如果没消费过，才更新数据，然后标记消息为已消费。但该方案在分布式系统中比较复杂，高可用，高性能都有一定的影响，需要使用分布式锁或者分布式事务
* 对于无法处理的消息导致MQ重复发送，可以设置重复次数，过了重复次数将消息持久化到其他地方，比如死信队列，以后处理。

## 如何保证消息顺序

100%的顺序消息的条件比较苛刻，需要允许消息丢失且生成者到消费者到接收者都是单点单线程，一般是保证在不丢消息的前提下，尽量减少重复消息，不保证投递顺序。。

允许重复消息时，可以通过**版本号**或者**状态机**来解决消息幂等处理和消息顺序的问题

* **版本号**：消费者接收消息时，只接收比最新版本号大的消息，重复消息因为版本号比当前版本号小，所以可以抛弃，比如消息顺序是123，消费者当前也收到123了，再收到123其中一个就可以不进行处理了；如果消息顺序不一致，比如消息顺序是123，但先接收到的是3，1和2还没收到，那就只能先把3存起来，等待12的到来，具体可以参考TCP协议的通信机制。
* **状态机**：将业务流程设定成一系列的状态扭转，不同的状态只能处理不同的消息，就可以依靠状态流的扭转来实现顺序消息

**减少重复消息的处理**

消息队列收到消费者的确认信号后，将消息id清除或进行标记；

发送方要进行重发前对消费者进行询问请求

## 如何保证消息的可靠性传输

消息传输有3个阶段：

1. 消息的传输包括生产者发送消息给消息队列
2. 消息在Broker端存储，如果是集群，消息会复制到其他副本
3. 消费者通过pull模式拉取数据 或者 消息队列通过push模式向消费者发送消息

保证消息可靠，一般是使用 **持久化机制 或 事务 + ack机制**

持久化不一定带有事务特性，比如直接日志落地，如果持久化要实现事务特性，可以使用分布式事务或者本地数据库事务。

消息的确认机制（ack机制），消息发送完成后，需要收到接收方的确认信号，确认信号的返回可以是收到后消息后就立即返回，比如默认auto ack机制，或者是接收方法接收到消息，处理完该消息后才发送确认信号。另外，当接收方无法处理消息，比如消费能力不够，网络不佳等情况，接收方也可以直接拒绝消息，等待发送方重新发送，所以这里就涉及到消息的重复发送了，通过直接拒绝消息来减少业务负担。

> ACK模式描述了Consumer与broker确认消息的方式(时机),比如当消息被Consumer接收之后,Consumer将在何时确认消息。对于broker而言，只有接收到ACK指令,才会认为消息被正确的接收或者处理成功了,通过ACK，可以在consumer（producer）与Broker之间建立一种简单的“担保”机制. 

1. 消息发送阶段：生产者往Broker发送消息前，可以做一次消息持久化，收到Broker的ack响应后，要正确处理，以此保证消息在生产阶段不会丢失。在此阶段，Broker并不关心生产者是否收到ack响应，因为在生产者的角度，消息已经持久化后成功发出了，如果没有收到ack，最多就重复发送，那就会收到重复的ack，保证消息一定落到了Broker，当然前提是Broker能幂等处理。

   发送方只有在消息入库成功，事务提交后，才会发送消息，如果发送失败，可以靠定时任务重试。注意本地事务做的是业务落地和消息落地的事务。

2. 消息到达Broker阶段：对于单节点Broker，在收到消息后，将消息持久化到磁盘，再给生产者返回ack响应；对于集群Broker，在收到消息后，至少要把消息发送到两个以上节点，再给生产者返回ack响应。

3. 消息消费阶段：对于pull模式，消费者拉取消息后，先成功执行完业务逻辑后，才给Broker发送消费ack响应，如果Broker没有收到消费者的确认响应，下次拉取的仍然是同一条消息。

   支持广播的消息队列需要对每个待发送的endpoint，持久化一个发送状态，直到所有endpoint状态都OK才可删除消息。

   无论是pull模式还是push模式，在允许重复消息的情况下，还可通过定时任务轮询未消费消息发送给消费者处理来保证最终一致性。

保证消息从生产者到MQ或者MQ到消费者的过程在同一个会话中，保证原子性；在事务性会话中，当一个事务被提交的时候，确认自动发生；事务回滚，消息再次传送；一个事务提交才能进行下个事务，效率较差。

在非事务性会话中，消息何时被确认取决于创建会话时的应答模式ACK模式，分为自动确认(onMessage方法成功返回，如果抛异常会交由异常消息监听器，或者重复次数发送)、手动确认、不必须确认,批量(重复有标记)。

**检测消息丢失的方法**

通过消息队列的有序性来验证是否有消息丢失。生产者发出消息时附加一个连续递增的序号，由消费者来检查这个序号的连续性。在分布式系统上，在发送消息时必须指定分区，消费者在每个分区单独检查消息序号的连续性。

**消息的丢失处理**

生产者消息丢失处理：发送消息时产生一个id，MQ接收到消息后回传id，超过一定时间没收到则重发

MQ消息丢失处理：开启消息队列持久化 和 消息持久化，持久化后才回传id给生产者

消费者消息丢失处理：取消自动ack，在方法处理完之后调用方法，发送确认ack给MQ，如果消息处理的时间太长，但可能导致重复发送

## 关于pull模式和push模式

* push模式的弊端，如果消费者消费能力不够，就会导致消息在消息队列中堆积，消息队列也需要保存这些消息，记录这些消息的状态；而pull模式是消费者按能力消费，所以没有这样问题。
* push模式下要保证顺序消息也比较麻烦，需要等待消费者确认一个消息后才能发送下一个，吞吐量就不太行了
* pull模式的弊端，因为消费者拉取消息的时间间隔比较难把握，间隔时间不合理就会导致消息消费存在延迟和忙等，常见的作法是消费者建立连接后hold住一段时间，保存一个长连接，设置等待时间进行断开，在这段时间内进行消息消费

## 如何解决消息队列的延时以及过期失效问题？

手动查询丢失消息，重新导入

对于activeMQ，可以设置死信队列，过期或者重复多次为被消费的消息会进入死信队列，activeMQ有提供方法处理死信队列

## 如何解决消息积压问题？

一般消息积压，要不就是发送快了，要不就是消费慢了，一般先查MQ监控，判断生产速度和消费速度是否异常。

* 生产者发送消息太慢也会导致积压，比如，生产者在一个事务内先发送半消息，处理业务逻辑，提交事务，事务成功后才会提交半消息，此时该消息才会被消费者所见，如果事务处理得太慢，也会造成消息堆积。

  so 生产者最好可以支持批量发送或者并行发送两种发送方式；对于实时性不强的业务，生产者可以积累一定量的消息才发送给MQ；对于批量发送的消息，消费时也要批量消费

* 修复消费者，检查消费者是不是对某一消息进行重复消费，恢复消费速度；

* 扩充原来的数量，消费之后再恢复原来架构。比如新键一个topic，建立比原先多n倍的队列，多n倍的消费者处理，每批消费者对应一个队列（分区），确保消费者的实例数和队列(分区)数相等。

* 如果可以持久化消息，耶可以先丢弃消息，之后再将持久化消息导入队列再处理
* 服务降级，减少生产者的发送消息的数量

# 延迟队列

[几种延迟队列实现](https://zhuanlan.zhihu.com/p/266156267)

# 参考

[消息队列常见问题和解决方案](http://xuyangyang.club/articles/2018/07/23/1532348839398.html)

[如何从0到1设计一个MQ消息队列](http://youzhixueyuan.com/design-the-message-queue.html)

[ActiveMQ消息传送机制以及ACK机制详解](https://shift-alt-ctrl.iteye.com/blog/2020182)

[架构文摘：消息队列设计精要](https://blog.csdn.net/zhaobryant/article/details/80557103)

[消息队列设计精要](https://tech.meituan.com/2016/07/01/mq-design.html)，这个讲的不错

极客时间 - 消息队列高手课 - 李玥

