[TOC]

# Quartz

* 分为三个部分：e
  * Job&Detial(任务)：定时任务的执行方法，与Trigger配套的
  * Trigger(触发器)：规定什么时候触发，与Job&Detail配套的
  * Scheduler(调度器)：单例，把Trigger丢里面由调度器调度，只需要一个Scheduler，配置不同的Trigger；可以理解成类似线程池的东西

* 原理：ScheduledThreadPoolExecutor线程池 + 通过Object类的wait()和notify()或者Condition类的await()\signal()进行等待和唤醒、锁保证线程安全 来进行调度

  Scheduler有两个调度线程：regular Scheduler Thread（执行常规调度）和Misfire Scheduler Thread（执行错失的任务），Regular Thread 轮询所有Trigger，如果有将要触发的Trigger（用wait和notifyAll实现），则从任务线程池中获取一个空闲线程，然后执行与改Trigger关联的job；Misfire Thraed则是扫描所有的trigger，查看是否有错失的，如果有的话，根据一定的策略进行处理

* 默认是并发的，即如果当前任务没有完成，会自动开一个任务执行

* 注意在分布式集群的情况下，多台机子有相同的定时任务，会出错，此时通过共享数据库的方式实现

  Quartz的解决方案：

  quartz集群分为水平集群和垂直集群，水平集群即将定时任务节点部署在不同的服务器，其最大的问题就是时钟同步问题，若时钟不能同步，则会导致集群中各个节点状态紊乱，造成不可预知的后果；垂直集群则是集群各节点部署在同一台服务器，时钟同步自然不是问题，但存在单点故障问题，服务器宕机会严重影响服务的可用性

  在各个节点会上报任务，存到数据库中，执行时会从数据库中取出触发器来执行，如果触发器的名称和执行时间相同，则只有一个节点去执行此任务。

  如果此节点执行失败，则此任务则会被分派到另一节点执行，中途也会自动检查失效的定时调度，发现不成功的，其他节点立马接过来继续完成定时任务。Quartz有11个定时任务调度表

参考

[Quartz原理解密](https://www.cnblogs.com/Dorae/p/9357180.html)

[深入解读Quartz的原理](https://blog.csdn.net/scgyus/article/details/79360316)

[Quartz 2.2 的实现原理和运行过程](https://blog.csdn.net/xlxxcc/article/details/52104463)

## 其他定时器

  * Timer：这是java自带的java.util.Timer类，这个类允许你调度一个java.util.TimerTask任务。使用这种方式可以让你的程序按照某一个频度执行，但不能在指定时间运行。一般用的较少。单线程，任务一多会阻塞；一个任务出异常其他任务都受影响；受系统时间影响
  * ScheduledExecutorService：也jdk自带的一个类；是基于线程池设计的定时任务类,每个调度任务都会分配到线程池中的一个线程去执行,也就是说,任务是并发执行,互不影响。线程池+延时队列DelayedQueue(数组、最小堆, 最近要执行的任务放在堆顶) 实现，如果堆顶任务时间未到就阻塞（通过自旋+condition.await\signal实现）。不受系统时间影响
  * Spring 中的 @Schedule  注解

参考：[Java 定时任务实现原理详解](https://blog.csdn.net/u013332124/article/details/79603943)

[Java优先级队列DelayedWorkQueue原理分析](https://www.jianshu.com/p/587901245c95)

# 限流

限流的方案也可以使用Redis做，比如使用Lua脚本实现某个ip一分钟内的访问次数限制。

## 固定窗口

规定单位时间内可访问的次数，比如规定接口一分钟内只能访问10次，以第一次请求为起始，计数1，一分钟内计数超过10后，后续的请求直接拒绝，只能等到这一分钟结束后，重置计数，重新开始计数。

但是这样有个问题，如果在大部分请求集中在第一个窗口的后10s内，和第二个窗口的前10s内，虽然他们都符合限流策略，但是在临界的20s内，请求还是有可能压垮系统。

## 滑动窗口

与固定窗口类似，只是以时间片划分，比如规定接口一秒内只能请求5次，每次请求时会按照前一秒内的请求数量进行判断，超过则拒绝。

可以使用循环队列，比如当有新请求进来时，删除队列中与这个新请求的时间间隔超过1s的请求，然后判断循环队列中是否有空闲位置，如果有就将新请求存入队列尾部。如果有，说明1s内的已超请求次数。

## 漏桶

控制流水，一般使用消息队列实现，定期消费

一般用在对第三方提供服务的请求限制上，比如我们服务接入shopify的服务，为了不触发shopify的限流，就可以使用漏桶算法。

## 令牌桶

类似信号量，令牌桶会单独维护一个令牌的存储桶，为这个桶设置一个上限，同时又会有令牌持续将放入桶中，以应对一定的突发流量，比如桶的上限是1000，每秒持续放入1000个令牌，当前1s有800个请求发生并消耗令牌，由于每秒会放入1000个令牌，后1s就有1200个令牌可以被消耗，因此下一秒可以应对1200个请求。

漏桶和令牌桶的区别：漏桶是限制流出速度，令牌桶是限制流入速度。

# 熔断

熔断一般分为三种状态：

* Closed关闭：服务正常时，熔断处于关闭状态
* Open开启：当我们设定10s的滑动窗口内错误率达90%，则从Closed变为Open状态
* HalfOpen半开启：再经过10s的窗口期，此时从Open状态转为HalfOpen状态，按照 `0.5 * (Now() - Start()) / Duration `的公式放量，直到成功率变为90%，转为Closed状态，否则转为Open状态。

滑动窗口的时间不能设置太长，否则熔断恢复时间也会变长；错误统计只统计系统异常不通知业务异常。

# CORS

前后端分离的场景下，由于浏览器的同源策略，导致浏览器内的请求不同的源的后端是会失败，常见的解决跨域方法是使用CORS，现在常见的web框架都支持CORS，开启即可

浏览器的同源策略限制：无法获取不同源的DOM、cookie、LocalStorage、不同源无法正常使用ajax请求。

解决跨域的方法除了CORS，还有jsonp，不过已经很少使用了，jsonp本质是利用浏览器允许加载不同源的js文件即<script>标签等，将跨域请求<script>标签里，返回一段可执行的js代码，其中包含了请求结果，通常是json格式，前端通过返回的js代码执行回调获取结果

详情见 [跨域资源共享 CORS 详解](http://www.ruanyifeng.com/blog/2016/04/cors.html)

对于跨域产生的问题，如CSRF跨域请求攻击的解决方案，可参考：[美团:如何防止csrf](https://tech.meituan.com/2018/10/11/fe-security-csrf.html)

# session和cookie

- 首先Http是无状态的，因此需要通过session、cookie来达到记录用户状态的目的。

- 传统的session、cookie：session存用户信息，保存在服务端中，cookie里存session对应的sessionId，保存在客户端中，用于找到对应的session，每次请求都会带上该cookie来表示此用户。

- 由于现在实例的部署不可能只部署一个，一般都是集群部署，因此session不可以只存在一个实例的内存中，因此引入Redis来存用户的登录信息

- 现在一般使用 token + Redis来实现session机制，前端的cookie更多的是存token的信息而已，一般也是把token的值放在请求头中，而不会把cookie发给后端

# JWT

JWT = JSON WEB TOKEN

## 原理

JWT实际上是一个token(令牌)，分为三部分：Header(头部)、Payload(负载)、Signature(签名)。

Header(头部) ：两部分组成，记录令牌类型和JWT的签名算法，一般是HMACSHA256。

Payload(负载)： 记录用户登录信息(官方规范默认是不加密的，分为官方字段和私有字段）。

Signature(签名) ：记录将 Header、Payload和服务端的密钥组合起来，使用Header(头部)里规定的方式加密。

比如header里保存的加密方式是HMACSHA256，`签名 Signature = HMACSHA256(base64URL(header) + "." + base64URL(payload) + "." + 保存在后端的密钥)`

最后的JWT = `base64URL(Header) + "." + base64URL(Payload) + "." + Signature`，后端收到该JWT后验证该签名是否正确，来判断JWT里的用户信息是否可靠。

**base64**：64指的是A-Z,a-z，0-9，+，/，将待转换的字符串转成二进制流，每3个8位转成4个6位，6位的二进制数转成十进制，根据码表找到对应的字符，以=号做后缀，凑齐位数

一般是为了解决一些字符编码的问题，将非ASCII字符转化为ASCII字符，还有就是可以对数据做简单加密，base64URL在base64的基础上增加对一些符号的编解码，比如把"-"替换成"+"，使得它可以出现在url中。

**HMACSHA256**：摘要算法，一般用于验证签名是否一致

## 使用

可以存储在浏览器的本地缓存localStorage或者cookie中，发送请求的时候放在cookie里，或者放在请求头中

- JWT的目的是让服务器不保存任何session数据，让后端变成无状态的，因此没办法主动废弃某个token，一旦签发了JWT，在到期之前就会始终有效，如果想要实现这种功能，必然需要在后端保存JWT，就违背了JWT的设计初衷了。
- 要让JWT实现 续签 和 主动过期功能，必定需要在后端保存JWT
  - jwt主动过期问题，使用黑名单即可；分成两点，客户端要求失效，服务端记录token到黑名单；用户重置密码，服务端记录uid-time键值对，在此之前的token全部失效；客户端把保存的jwt删掉是没用的，此时的jwt依然有效，只是客户端没记录而已
  - jwt续签问题，一种解决方式是jwt中存储过期时间，服务端设置刷新时间，请求时判断是否在过期时间或刷新时间，在刷新时间内进行token刷新，失效token记入黑名单；
  - 而黑名单过大问题，可以采用记录UID-刷新时间方式解决，判断jwt签发时间，jwt签发时间小于UID-刷新时间的记为失效
- 个人认为JWT的生成方式本身是有一套规范的，在实际使用过程中也可以对他进行改动，本质上还是一个签名校验而已，一般会对JWT进行魔改，比如使用Header(头部)里的加密方式加密Signature(签名)，Signature(签名)加密Header(头部) 和Payload(负载) 这两部分，服务器里的私钥解密Payload(负载)，得到需要的登录信息，不通过简单的base64URL编码，不对外暴露，签名算法或者签名里的密钥的方式可以改成其他等。

JWT参考：[JWT 超详细分析](https://learnku.com/articles/17883)

# CAS模型 - SSO(单点登录)

可参考：[CAS实现单点登录SSO执行原理探究](https://blog.csdn.net/javaloveiphone/article/details/52439613)，讲得算是比较明白，这里是总结基于CAS模式改的单点登录模式

- 第一次访问时，由于没有访问的token，会引导至登录

![第一次访问](https://github.com/Nixum/Java-Note/raw/master/Note/picture/sso-first-access.png)

- 再次访问Web-1时，由于前端已存了token，直接使用token进行请求即可

- 已登录Web-1时去访问Web-2，会通过后端认证中心实现单点登录

![第二次访问](https://github.com/Nixum/Java-Note/raw/master/Note/picture/sso-second-access.png)

这里在总结一下关于GrantTicket和ServiceTicket，跟CAS模型中提到的TGT、ST、PGT这些东西是类似的，本质是作为验证的票据，图中的GrantTicket、ServiceTicket、token含义如下

GrantTicket：全局会话票据，保存在登录页，通过GrantTicket才能换取ServiceTicket；

ServiceTicket表示访问资源的一次性票据，根据ServiceTicket换取token，换取后失效；

token：登录凭证

GT、ST和token都是保存在Redis中的，他们在Redis中的存储结构如下

```
key：TOKEN_${Token的值}
value:
{
    "createTime": 1565961654807,
    "accountId": "123",
    // 用户其他信息
    "grantTicket": ${GrantTicket的值}  // token关联GT，用于注销时实现全局注销
}

key：GRANT_TICKET_${GrantTicket的值}
value:
{
    "createTime": 1565961654807,
    "accountId": "123",
}

key：SERVICE_TICKET_${ServiceTicket的值}
value:
{
    "createTime": 1565961654807,
    "grantTicket": ${GrantTicket的值} // ST关联GT，用于判断该ST是否有效，换取token后删除
}

// token与grantTicket的记录，注销时，根据token中关联的GT，找到所有与之关联的token，进行删除，这里推荐使用Redis的scan命令进行分段查询，原因是Redis是单线程的，如果数据量太大使用keys命令遍历太久，阻塞Redis接收其他命令
key：{grantTicket}-{token}
value：无
```

# 基于OAuth2.0的第三方登录

可参考：[理解OAuth 2.0](https://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html)，这样基本就入门了，这里是总结项目中如何接入，一般在集成facebook和google的第三方登录也是类似的流程机制，这里只用到了access_token，对于refresh_token，是用来延长access_token的过期时间的，减少短时间内的重复登录，这里就没有涉及到了

![基于OAuth2的第三方登录](https://github.com/Nixum/Java-Note/raw/master/Note/picture/基于oauth2的第三方登录流程.png)

为什么要后端要根据code + clientId + secret换成access_token，再根据access_token换用户个人信息？

为什么后端不直接code + clientId + secret换用户个人信息呢？

主要还是为了安全，防止中间人攻击

* 重定向的参数是带在url里的，是直接暴露在客户端的，如果直接返回access_token就不安全，因此才多了code这一层，为了降低code被拦截泄漏后的风险，code的过期时间一般都很短，且是一次性的；

* 另外就是后端对于外部的请求都是不信任的，因此接收到的参数(code)首先还要配合凭证去验证其合法性，对于验证通过后获得的access_token也有更多的操作空间，由后端持有，不会暴露出去

  像上图那种登录方案，后端只需要用户个人信息换完token就算完事了，所以看起来好像直接使用code + clientId + secret换用户个人信息就行，但是如果此时需要再获取用户的其他信息，就没有没办法再用code去换了，只能要求用户再次登录，此时如果有access_token就显得多么重要了

# 压测

总结一下做过的压测，压测工具jmetter，利用jmette可以多线程并发请求和可以实时查看简易报告的能力

1. 先对被压测服务的接口针对不同场景编写压测用例，设定好TPS的起始和目标值，作为压测计划

2. 画压测机器部署关系图，部署压测环境

   *  对于被压测的服务，一般会mock掉与该服务相关关联的服务，比如该服务还连了数据库，该接口请求依赖一些独立部署的中间件，或者依赖其他服务，则会对这些相关的依赖用桩来代替，用于维持通信，以减少这些额外服务的影响。

   * 一般一台机器只部署一个服务，特别是被压测服务，此外还要注意被压测服务所在的机器上网络设置相关的参数，比如TCP最大连接数、回收策略之类的设置

3. 编写压测脚本，压测脚本越简单越好，尽量让压测工具不影响被压测服务，**脚本最重要的几个设置**： 发起请求时的并发线程数、响应的断言、TPS数，其他那些花里胡哨的输出树状图，饼图啊那些都不用配了，用最简单的报告输出即可

4. 部署完后，将脚本配置放到jmeter的机器上，启动压测

   ```
   nohup java -jar bin/ApacheJMeter.jar -n -t jmetter脚本路径/config.jmx > test.out &
   ```

   输出到当前目录下的test.out文件里，这里启动是使用默认参数启动，如果对jmetter的JVM设置有要求，也可以在启动时指定JVM参数，如

   ```
   nohup java -server -XX:+HeapDumpOnOutOfMemoryError -Xms512m -Xmx512m -XX:+UseG1GC -XX:MaxGCPauseMillis=250 -XX:G1ReservePercent=20 -Djava.security.egd=file:/dev/urandom -jar bin/ApacheJMeter.jar -n -t jmetter脚本路径/config.jmx > test.out &
   ```

   压测开启后可以打开test.out文件查看压测报告

5. 一般是按照TPS从小往大压，小的TPS压，在正常延时的情况下可以先判断程序是否有问题，比如内存泄漏，内存溢出，没问题了再逐步往大了压。如果先从大往小压，延时又上不去，此时判断不了是程序内部问题还是过大的TPS导致。压测时间一般最少压一天

6. 输出压测报告

一般有如下几个点要注意，这些点到时也要输出到压测报告上

| 监控点                                | 说明                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| jmetter端的TPS、延时、错误率          | 观察TPS是否符合预期、延时是否达到预期且稳定、错误率要为0。**当程序正常时降低RT的手段**：减少不必要的日志输出、业务逻辑算法是否还有优化空间，是否有IO占用或者频繁序列化反序列化、内部队列是否阻塞 |
| 被压测服务的gc                        | fgc，ygc不要太频繁，一般来说**fgc 一小时要小于3~4次**；**ygc一分钟要小于3~4次为佳**。 |
| jmetter端的CPU、内存使用率等          | 注意jmetter端的CPU是否过高或波动很大，避免影响压测结论       |
| 被压测服务端的CPU、磁盘、内存使用率等 | 如果cpu过高，如果连续达到90以上，基本上是内存泄漏导致了频繁的fgc；磁盘的占用情况，注意生成的日志是否把磁盘占满了 |

使用 `jstat -gcutil [pid] [时间间隔，每几秒打印] [打印次数]`查看GC情况

当被压测端的gc不正常时，应尽量保存事发环境

​	1、收集内存使用基本情况统计：`jmap -heap [pid] > [文件名，如heap.log]`


​	2、收集线程堆栈运行信息：`jstack [pid] > [文件名，如stack.log]`

​	3、收集内存详细使用信息，生成dump内存快照：`jmap -dump:format=b,file=[文件名，如heap.dump] [pid]`


一般使用eclipse mat工具进行内存快照的分析，排查出内存泄漏的问题。

mat的使用参见：[Eclipse MAT内存分析工具](https://www.cnblogs.com/yueshutong/p/9824772.html)

**一般压测脚本的模板：**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<jmeterTestPlan version="1.2" properties="3.2" jmeter="3.2 r1790748">
  <hashTree>
    <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="测试计划" enabled="true">
        <!-- 一般写压测计划中的序号+名称 -->
      <stringProp name="TestPlan.comments"></stringProp>
      <boolProp name="TestPlan.functional_mode">false</boolProp>
      <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
      <elementProp name="TestPlan.user_defined_variables" elementType="Arguments" guiclass="ArgumentsPanel" testclass="Arguments" testname="用户定义的变量" enabled="true">
        <collectionProp name="Arguments.arguments"/>
      </elementProp>
      <stringProp name="TestPlan.user_define_classpath"></stringProp>
    </TestPlan>
    <hashTree>
      <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="Thread Group" enabled="true">
        <stringProp name="ThreadGroup.on_sample_error">continue</stringProp>
        <elementProp name="ThreadGroup.main_controller" elementType="LoopController" guiclass="LoopControlPanel" testclass="LoopController" testname="循环控制器" enabled="true">
          <boolProp name="LoopController.continue_forever">false</boolProp>
          <intProp name="LoopController.loops">-1</intProp>
        </elementProp>
        <stringProp name="ThreadGroup.num_threads">500</stringProp>                                             <!-- 发起请求时的并发线程数，这里设置为500个并发线程，表示使用这么多的线程数来达到下面设置的TPS数 -->
        <stringProp name="ThreadGroup.ramp_time">8</stringProp>
        <longProp name="ThreadGroup.start_time">1509332694000</longProp>
        <longProp name="ThreadGroup.end_time">1509332694000</longProp>
        <boolProp name="ThreadGroup.scheduler">false</boolProp>
        <stringProp name="ThreadGroup.duration"></stringProp>
        <stringProp name="ThreadGroup.delay"></stringProp>
      </ThreadGroup>
      <hashTree>
        <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="click http request" enabled="true">
          <elementProp name="HTTPsampler.Arguments" elementType="Arguments" guiclass="HTTPArgumentsPanel" testclass="Arguments" testname="用户定义的变量" enabled="true">
            <collectionProp name="Arguments.arguments"/>
          </elementProp>
          <stringProp name="HTTPSampler.domain">192.168.1.123</stringProp>         <!-- 此处为被压测服务的host -->
          <stringProp name="HTTPSampler.port">12345</stringProp>                    <!-- 此处为被压测服务的port -->
          <stringProp name="HTTPSampler.protocol">http</stringProp>
          <stringProp name="HTTPSampler.contentEncoding"></stringProp>
          <stringProp name="HTTPSampler.path">${__StringFromFile(/home/urls.log,,,)}</stringProp>  <!-- 发起的http请求uri从文件读取，文件路径 -->
          <stringProp name="HTTPSampler.method">GET</stringProp>
          <boolProp name="HTTPSampler.follow_redirects">false</boolProp>
          <boolProp name="HTTPSampler.auto_redirects">false</boolProp>
          <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
          <boolProp name="HTTPSampler.DO_MULTIPART_POST">false</boolProp>
          <stringProp name="HTTPSampler.embedded_url_re"></stringProp>
          <stringProp name="HTTPSampler.implementation">Java</stringProp>
          <stringProp name="HTTPSampler.connect_timeout"></stringProp>
          <stringProp name="HTTPSampler.response_timeout"></stringProp>
        </HTTPSamplerProxy>
        <hashTree/>
        <ResponseAssertion guiclass="AssertionGui" testclass="ResponseAssertion" testname="Response Assertion" enabled="true">
          <collectionProp name="Asserion.test_strings">
            <stringProp name="49586">200</stringProp>                                       <!-- http请求的响应断言，要求返回的http code为200才判定为成功 -->
          </collectionProp>
          <stringProp name="Assertion.test_field">Assertion.response_code</stringProp>
          <boolProp name="Assertion.assume_success">false</boolProp>
          <intProp name="Assertion.test_type">8</intProp>
        </ResponseAssertion>
        <hashTree/>
        <ConstantThroughputTimer guiclass="TestBeanGUI" testclass="ConstantThroughputTimer" testname="Constant Throughput Timer" enabled="true">
          <intProp name="calcMode">1</intProp>
          <doubleProp>
            <name>throughput</name>
            <value>30000.0</value>          <!-- 1分钟内发起的请求数，换算为tps为500 -->
            <savedValue>0.0</savedValue>
          </doubleProp>
        </ConstantThroughputTimer>
        <hashTree/>
      </hashTree>
    </hashTree>
    <WorkBench guiclass="WorkBenchGui" testclass="WorkBench" testname="工作台" enabled="true">
      <boolProp name="WorkBench.save">true</boolProp>
    </WorkBench>
    <hashTree/>
  </hashTree>
</jmeterTestPlan>
```

# 调优

参考：https://tech.meituan.com/2016/12/02/performance-tunning.html

# 业务相关

## 防止表单重复提交

**场景**：用户点击下单页面，跳转至下单页面，提交订单，此时有可能网络原因或者用户点击多次，导致订单重复提交。

**解决**：用户跳转至下单页前，会先获取订单号(也作为订单表主键)，将订单号绑定在下单页，利用数据库主键唯一的特性，让创建订单的操作变成幂等性。

## 解决ABA问题

**场景：**类似MySQL的丢失更新，比如有操作1，操作2先后对记录A进行更新，操作1的响应丢失导致重试，此时操作2已经更新成功，操作1重试时会覆盖操作2的更新。

**解决：**通过版本号解决，订单表增加一列作版本号，版本号可以使用递增序列、时间戳等，通过比较版本号来确定操作的先后顺序，更新成功时也需要更新版本号。

## 流量大、数据量大的商品详情页数据存储

**场景：**一般商品详情页都是访问量最大的页面，比如用户做商品对比、查看商品详情都需要，另外就是商品详情页一般涉及很多数据，如下，且后端存储的sku量也是巨大的，直接分多张表去存虽然可以实现，但是性能就一般了。

```
商品
├── 基本信息
│    ├── 标题、副标题
│    ├── 价格：原价、促销价
│    └── 颜色、规格等
├── 商品参数
├── 商品介绍
├── 图片视频
来自其他系统的
├── 促销信息
├── 推荐商品
├── 评论、评价
├── 配送信息
└── 店铺信息
```

**解决：**分析不同的数据特性，比如有些数据是热点的、相对固定的、不常被修改的、需求变化不大的等各种维度去划分，进行不同存储。动态数据、实时数据还是照旧，该怎么处理怎么处理，其他的可以：

1. 套一层缓存在数据库外面，查询数据先缓存后数据库

2. 针对每个不同的spu有不同的商品属性，则可以使用NoSQL来解决

3. 针对图片、视频等数据，使用对象存储、CDN解决，比如AWS S3，直接通过其提供的API进行访问，将这部分的压力转移到云服务厂商

4. 将相对固定的数据静态化，比如商品介绍，其包含了大量的文字、图片、视频等，可直接将这一部分保存成HTML文件中，访问时直接返回HTML文件，保存成HTML还可以配合CDN进行加速

## 针对SQL方面的优化

* 可以起一个SQL检查脚本，检查执行时间过长的SQL，如果超过指定时间的，进行记录和kill，再进行优化，把慢SQL解决掉，避免多个执行时间过长的SQL拖垮整个数据库。
* 主从分离，读写分离，服务降级
* 分析SQL执行和访问量间的关系，数据库CPU利用率变化
* MySQL单次查询扫描的数据量控制在千万级别内，单次扫描的数据量在百万级别是可以接受，理论上查询都应该使用索引，避免全表扫描

## 对象存储原理

* 本质是一个规模很大的分布式Key-value集群，外加一个保存集群节点信息、文件信息和映射关系(统称为元数据)的节点集群，在最外层再加上一个Gateway来对外提供服务即可。
* 针对图片、视频等大文件，在存储时会将其拆分成多个大小相等的块Block，一般是几十KB到几MB，便于管理，也可以分散到不同节点，提升并行读写性能。
* 由于分成的块太小，数量多，一般也不是直接进行管理的，而是将一些块进行聚合，放到容器里，类似分片的概念，主从复制时，也是直接复制这些块即可，不用再复制多日志

## 跨系统数据实时同步

* 采用Bin Log + MQ的方式，将上游数据实时同步到下游其他系统的数据库中，为了确保数据一致性，必须顺序读取Bin Log，因此MQ的主题也必须设置为只有一个分区，才能保证Bin Log有序。
* 当下游系统想要扩展消费能力时，不可盲目增加同步线程数和MQ主题分区，由于Bin Log的顺序性，要确保多线程消费时，不会对数据产生影响，所以可以将具有因果一致性的Bin Log发布给同一主题分区，才可以多线程同步消费。具体可参考MySQL 5.6版本后多线程处理Bin Log的做法。

## 不停机情况下更换数据库

* 利用Bin Log或者复制状态机理论，增加一个新库和同步服务。先将旧库上的数据快照同步到新库，对于旧库的新数据，使用同步服务进行同步复制
* 改造旧服务，增加双写新旧两个库的功能，添加功能开关，使其能够只写旧库、只写新库、同步双写的功能
* 开关打至只写旧服务，利用同步服务同步数据，等改造后的旧服务能稳定运行，验证新旧两个库的数据是否一致；一致之后将改造后的旧服务的开关打至同步双写，关闭同步服务，此时仍然以数据写至旧库为主，写新库失败则进行人工干预，此外，双写时可能会存在数据不一致，此时需要针对这一小段时期上线数据对比与补偿服务，验证和补充新旧数据不一致问题；待最终稳定后，才将开关打至只写新服务，实现数据库替换的平滑过渡。

## 海量数据处理

针对的是埋点数据、日志数据、访问数据、点击数据、监控数据等，一般采用先存储后计算的方式

* 使用Kafka存储，上游系统将海量数据采集后发给KafKa，利用Kafka无限消息堆积和超高吞吐，存储数据，再由下游系统进行订阅消费即可。这种方案适合短时间的海量数据处理。关键词：分布式流数据存储。
* HDFS存储 + Hive查询 或者 ES查询
* 针对监控数据，可以使用时序数据库，例如Prometheus

## API协议设计

其实分成了API和协议两部分

* 一般API会符合Restful规范，由行为 + 资源组合而成；
* 协议一般就包含了请求/响应头和响应/请求体的内容，参数结构化，比如参数类型是Hash，就不要存成String，值是Hash的序列化后的字符串；
* 响应结果要统一，尽量不要因为参数的不同而返回不同类型的响应结构
* 需要考虑认证和安全相关，比如是否需要签名、票据、token等
* 多服务之间，保证风格一致
* 考虑幂等；
* 加入版本控制，加在URL上，或者请求头有个字段标识；



# 参考

极客时间 - 后端存储实战

